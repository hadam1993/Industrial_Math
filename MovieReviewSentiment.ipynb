{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie review sentiment analysis\n",
    "\n",
    "In this first example, we will use a pre-cleaned dataset of text snippets from movie reviews with sentiment classification, telling us if the snippet says something positive or negative about the movie.\n",
    "\n",
    "We will first use BERT to convert the text snippets into embeddings which, in combination with the classifications, we will then use to train, validate, and test a simple neural network and compare the results to a logistic regression analysis of the same data sets.\n",
    "\n",
    "The logistic regression model is taken from the scikit learn package; for the implementation of the neural network the pytorch package is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions which we can reuse, since we will do the same operations on multiple sub-datasets:\n",
    "1) Pad the token lists in a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_token_list(sample):\n",
    "    # Find the sentence with the max length\n",
    "    max_len = 0\n",
    "    for token_list in sample:\n",
    "        if len(token_list) > max_len:\n",
    "            max_len = len(token_list)\n",
    "    # Adjust every sentence to the same length\n",
    "    padded = np.array([i + [0]*(max_len-len(token_list)) for token_list in sample])\n",
    "    return padded, max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the data using pandas, since it is stored as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/SST2/train.tsv',delimiter='\\t',header=None,\\\n",
    "                           names=['sentence','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a random sample from our dataset to use for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = dataset.sample(n=sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the rest as verification dataset to compare the to approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = dataset.iloc[dataset.index.difference(random_sample.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show distribution of positive and negative classifications in our random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained, downsized version of BERT, DistilBERT:  \n",
    "- We need a tokenizer, to split the snippets into single words\n",
    "- We need the model itself to convert the words into embedding vectors of size 768\n",
    "- For both of those, we need trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply tokenizer to both the sample and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tokenized = random_sample['sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "test_tokenized = test_set['sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure of tokenized snippets:  \n",
    "The labels have not changed, but instead of one long string, we now have a list of single words as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tokenized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use BERT on this dataset, we need to have each snippet be of the same length. So we pad the shorter snippets with zeros at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_padded = pad_token_list(sample_tokenized)\n",
    "test_padded = pad_token_list(test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure of padded dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create a mask for the padded dataset that shows the model which tokens were generated from actual data and which tokens are just padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_attention_mask = np.where(sample_padded != 0, 1, 0)\n",
    "test_attention_mask = np.where(test_padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First entry of sample_attention_mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_attention_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids = torch.tensor(test_padded)  \n",
    "test_attention_mask = torch.tensor(test_attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_last_hidden_states = model(test_input_ids, attention_mask=test_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = new_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, val_features, train_labels, val_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.score(val_features, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's feed it some of our own data (tricky!)\n",
    "s = [['I hate people who hate this movie',1],\n",
    "     ['I hate people who hate this movie, because I love it',1],\n",
    "     ['I love people who do not love this movie',0],\n",
    "     ['This movie is great',1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = df2[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded2 = np.array([i + [0]*(max_len-len(i)) for i in tokens2.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask2 = np.where(padded2 != 0, 1, 0)\n",
    "input_ids2 = torch.tensor(padded2)\n",
    "attention_mask2 = torch.tensor(attention_mask2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states2 = model(input_ids2, attention_mask=attention_mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = last_hidden_states2[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = df2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our output sentiment for the new reviews\n",
    "lr_clf.predict(features2)\n",
    "# Compared to the labels, we got 50% correct. YAY!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a neural net that gets better results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cuda device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tensor = torch.tensor(np.asarray(train_features))\n",
    "train_features_tensor = train_features_tensor.to(device)\n",
    "\n",
    "val_features_tensor =  torch.tensor(np.asarray(val_features))\n",
    "val_features_tensor = torch.tensor(val_features_tensor).to(device)\n",
    "\n",
    "test_features_tensor =  torch.tensor(np.asarray(test_features))\n",
    "test_features_tensor = torch.tensor(test_features_tensor).to(device)\n",
    "\n",
    "train_labels_tensor =  torch.tensor(np.asarray(train_labels))\n",
    "train_labels_tensor = torch.tensor(train_labels_tensor).to(device)\n",
    "\n",
    "val_labels_tensor = torch.tensor(np.asarray(val_labels))\n",
    "val_labels_tensor = torch.tensor(val_labels_tensor).to(device)\n",
    "\n",
    "test_labels_tensor = torch.tensor(np.asarray(test_labels))\n",
    "test_labels_tensor = torch.tensor(test_labels_tensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put our input data onto device\n",
    "last_hidden_states = last_hidden_states[0][:,0,:].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_hidden_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network class to be trained\n",
    "# Structure:\n",
    "# input -> fc1 -> sigmoid -> out -> log_softmax\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Shallow_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Shallow_Network,self).__init__()\n",
    "        self.fc1 = nn.Linear(768,1000)\n",
    "        self.out = nn.Linear(1000,2)\n",
    "    def forward(self,input):\n",
    "        # Take input, feed through fc1 layer,\n",
    "        # then apply activation function to it\n",
    "        x = F.sigmoid(self.fc1(input))\n",
    "        # Take output of sigmoid, input into out layer,\n",
    "        # and apply log_softmax function\n",
    "        return (F.log_softmax(self.out(x),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network object\n",
    "net = Shallow_Network()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export labels\n",
    "labels_tensor = torch.tensor(labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put on device\n",
    "labels_tensor = labels_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#Create an stochastic gradient descent optimizer\n",
    "adam = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_func = nn.NLLLoss()\n",
    "loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train network\n",
    "cnt = 0\n",
    "average_losses = []\n",
    "average_val_losses = []\n",
    "acc = []\n",
    "cur_loss = []\n",
    "min_validation = 10000.0\n",
    "for epoch in range(1000):\n",
    "    net.train()\n",
    "    #zero the gradient\n",
    "    adam.zero_grad()\n",
    "    #Get output of network\n",
    "    probs = net(train_features_tensor)\n",
    "    #compute loss\n",
    "    loss = loss_func(probs,train_labels_tensor)\n",
    "    #compute the backward gradient and move network in that direction\n",
    "    loss.backward()\n",
    "    adam.step()\n",
    "    #gather loss\n",
    "    cur_loss.append(loss.detach().cpu().numpy())\n",
    "    print(\"epoch \",epoch)\n",
    "    print(\"training loss: \", np.mean(cur_loss))\n",
    "    net.eval()\n",
    "    probs_val = net(test_features_tensor)\n",
    "    loss_val = loss_func(probs_val,test_labels_tensor)\n",
    "    print(\"validation loss: \", np.mean(loss_val.detach().cpu().numpy()))\n",
    "    #Save model if validation is min\n",
    "    if min_validation > np.mean(loss_val.detach().cpu().numpy()):\n",
    "        min_validation = np.mean(loss_val.detach().cpu().numpy())\n",
    "        torch.save(net.state_dict(), './net_parameters_%d.pth' % epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Shallow_Network()\n",
    "checkpoint = torch.load('./net_parameters_147.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_val = model(val_features_tensor)\n",
    "loss_val = loss_func(probs_val,val_labels_tensor)\n",
    "print(\"validation loss: \", np.mean(loss_val.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classification probabilities from hidden state array\n",
    "# And apply Softmax\n",
    "with torch.no_grad():\n",
    "    probs = model(val_features_tensor)\n",
    "    softprobs = F.softmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(softprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most likely class and its index for each sample point\n",
    "values, indices = torch.max(softprobs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted labels\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take original labels\n",
    "labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of sample points where prediction failed\n",
    "nums = torch.sum(torch.abs(val_labels_tensor-indices)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of correct predictions\n",
    "numcorrect = 2000-(nums+0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of prediction\n",
    "accuracy = numcorrect/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.asarray(indices.detach().cpu().numpy())\n",
    "lbls = np.asarray(labels_tensor.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.iloc[np.where(idx-lbls)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using test set\n",
    "probs_test = model(test_features_tensor)\n",
    "loss_test = loss_func(probs_test,test_labels_tensor)\n",
    "print(\"test loss: \", np.mean(loss_test.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    probs_test = model(test_features_tensor)\n",
    "    softprobs_test = F.softmax(probs_test)\n",
    "# Get most likely class and its index for each sample point\n",
    "test_values, test_indices = torch.max(softprobs_test,1)\n",
    "# Calculate number of sample points where prediction failed\n",
    "test_nums = torch.sum(torch.abs(test_labels_tensor-test_indices)).detach().cpu().numpy()\n",
    "# Number of correct predictions\n",
    "numcorrect = test_df.shape[0]-(test_nums+0)\n",
    "# Accuracy of prediction\n",
    "accuracy = numcorrect/test_df.shape[0]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
