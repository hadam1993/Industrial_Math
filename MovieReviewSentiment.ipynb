{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie review sentiment analysis\n",
    "\n",
    "##### In this first example, we will use a pre-cleaned dataset of text snippets from movie reviews with sentiment classification, telling us if the snippet says something positive or negative about the movie.\n",
    "\n",
    "##### We will first use BERT to convert the text snippets into embeddings which, in combination with the classifications, we will then use to train, validate, and test a simple neural network and compare the results to a logistic regression analysis of the same data sets.\n",
    "\n",
    "##### The logistic regression model is taken from the scikit-learn package; for the implementation of the neural network the pytorch package is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions which we can reuse, since we will do the same operations on multiple sub-datasets:\n",
    "##### 1) Sample sentences need to be of a uniform length as BERT input. So we need to pad the token lists in a sample with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_token_list(sample):\n",
    "    # Find the sentence with the max length\n",
    "    max_len = 0\n",
    "    for token_list in sample:\n",
    "        if len(token_list) > max_len:\n",
    "            max_len = len(token_list)\n",
    "    # Adjust every sentence to the same length\n",
    "    padded = np.array([token_list + [0]*(max_len-len(token_list)) for token_list in sample])\n",
    "    return padded, max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Extract embeddings from padded sample set. Conversion steps:\n",
    "- (Pad the tokenized list of sample sentences)\n",
    "- Create an attention mask where the padded tokens are identified with a 0 and the word tokens with a 1. This will help BERT distinguish between real data and padding\n",
    "- Create pytorch tensor objects\n",
    "- Feed the padded sample and the mask into BERT\n",
    "- Extract the embedding vector for the [CLS] token of each sample point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_sample(sample, model):\n",
    "    # Pad sample data:\n",
    "#     sample = pad_token_list(sample)\n",
    "    # Define mask from data: - 0 token entry     -> padding, set mask entry to 0\n",
    "    #                        - non-0 token entry -> valid word, set mask entry to 1\n",
    "    mask = np.where(sample != 0, 1, 0)\n",
    "    \n",
    "    # Create tensor objects from numpy arrays\n",
    "    input_ids = torch.tensor(sample).long()\n",
    "    attention_mask = torch.tensor(mask).long()\n",
    "\n",
    "    # Use BERT model to get embeddings\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    # Extract [CLS] embedding for each sample as numpy array to be used for classification task\n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    return features, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We read in the data using pandas, since it is stored as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/SST2/train.tsv',delimiter='\\t',header=None,\\\n",
    "                           names=['sentence','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Structure of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Take a random sample from our dataset to use for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = dataset.sample(n=sample_size)\n",
    "random_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will use the rest as verification dataset to compare the to approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = dataset.iloc[dataset.index.difference(random_sample.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show distribution of positive and negative classifications in our random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the pretrained, downsized version of BERT, DistilBERT:  \n",
    "- We need a tokenizer, to split the snippets into single words and convert those into integers (word identifiers)\n",
    "- We need the model itself to convert the word indentifiers into embedding vectors of size 768\n",
    "- For both of those tasks, we need pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply tokenizer to both the sample and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tokenized = random_sample['sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "test_tokenized = test_set['sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Structure of tokenized snippets:  \n",
    "##### The labels have not changed, but instead of one long string, we now have a list of single words as data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tokenized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To use BERT on this dataset, we need to have each snippet be of the same length. So we pad the shorter snippets with zeros at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_padded, sample_len = pad_token_list(sample_tokenized.values)\n",
    "test_padded, test_len = pad_token_list(test_tokenized.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Structure of padded dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate embeddings from sample data and extract [CLS] embedding which will be used for classification  \n",
    "##### The output shows the structure of the attention mask (for the first sample point) used in BERT to distinguish between real data and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features, mask = get_embeddings_from_sample(sample_padded, model)\n",
    "mask[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get embeddings for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, mask = get_embeddings_from_sample(sample_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get sentiment classification labels for sample and test set from input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels = random_sample['label']\n",
    "test_labels = test_set['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use scikit-learn's function train_test_split to randomly split up the sample into a training and a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, val_features, train_labels, val_labels = train_test_split(sample_features, sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By default, the data is split 75-25 into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create logistic regression model and feed it the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show score of validation training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.score(val_features, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As a test for the regression model, we will use some tricky snippets where negative words are used for a positive review, and vice versa.  \n",
    "##### Let's see how the model performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's feed it some of our own data (tricky!)\n",
    "s = [['I hate people who hate this movie',1],\n",
    "     ['I hate people who hate this movie, because I love it',1],\n",
    "     ['I love people who do not love this movie',0],\n",
    "     ['This movie is great',1]]\n",
    "trick_sample = pd.DataFrame(data=s, columns=['sentence','label'])\n",
    "trick_tokenized = trick_sample['sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "trick_padded = pad_token_list(trick_tokenized.values)\n",
    "trick_features, mask = get_embeddings_from_sample(trick_padded, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show the predicted sentiment for the new reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf.predict(trick_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compared to the manually assigned labels, we got 50% correct. Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a neural net that gets equal or better results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To speed up computation, we will perform the calculations on the graphics processor  \n",
    "##### We need to create a device for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cuda device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create tensor objects and transfer to device for all our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tensor = torch.tensor(np.asarray(train_features))\n",
    "train_features_tensor = train_features_tensor.to(device)\n",
    "\n",
    "val_features_tensor =  torch.tensor(np.asarray(val_features))\n",
    "val_features_tensor = torch.tensor(val_features_tensor).to(device)\n",
    "\n",
    "test_features_tensor =  torch.tensor(np.asarray(test_features))\n",
    "test_features_tensor = torch.tensor(test_features_tensor).to(device)\n",
    "\n",
    "trick_featues_tensor = torch.tensor(np.asarray(trick_features))\n",
    "trick_features_tensor = torch.tensor(trick_features_tensor).to(device)\n",
    "\n",
    "train_labels_tensor =  torch.tensor(np.asarray(train_labels))\n",
    "train_labels_tensor = torch.tensor(train_labels_tensor).to(device)\n",
    "\n",
    "val_labels_tensor = torch.tensor(np.asarray(val_labels))\n",
    "val_labels_tensor = torch.tensor(val_labels_tensor).to(device)\n",
    "\n",
    "test_labels_tensor = torch.tensor(np.asarray(test_labels))\n",
    "test_labels_tensor = torch.tensor(test_labels_tensor).to(device)\n",
    "\n",
    "trick_labels_tensor = torch.tensor(np.asarray(trick_sample['label']))\n",
    "trick_labels_tensor = torch.tensor(trick_labels_tensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put our input data onto device\n",
    "last_hidden_states = last_hidden_states[0][:,0,:].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_hidden_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network class to be trained\n",
    "# Structure:\n",
    "# input -> fc1 -> sigmoid -> out -> log_softmax\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Shallow_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Shallow_Network,self).__init__()\n",
    "        self.fc1 = nn.Linear(768,1000)\n",
    "        self.out = nn.Linear(1000,2)\n",
    "    def forward(self,input):\n",
    "        # Take input, feed through fc1 layer,\n",
    "        # then apply activation function to it\n",
    "        x = F.sigmoid(self.fc1(input))\n",
    "        # Take output of sigmoid, input into out layer,\n",
    "        # and apply log_softmax function\n",
    "        return (F.log_softmax(self.out(x),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network object\n",
    "net = Shallow_Network()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export labels\n",
    "labels_tensor = torch.tensor(labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put on device\n",
    "labels_tensor = labels_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#Create an stochastic gradient descent optimizer\n",
    "adam = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_func = nn.NLLLoss()\n",
    "loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train network\n",
    "cnt = 0\n",
    "average_losses = []\n",
    "average_val_losses = []\n",
    "acc = []\n",
    "cur_loss = []\n",
    "min_validation = 10000.0\n",
    "for epoch in range(1000):\n",
    "    net.train()\n",
    "    #zero the gradient\n",
    "    adam.zero_grad()\n",
    "    #Get output of network\n",
    "    probs = net(train_features_tensor)\n",
    "    #compute loss\n",
    "    loss = loss_func(probs,train_labels_tensor)\n",
    "    #compute the backward gradient and move network in that direction\n",
    "    loss.backward()\n",
    "    adam.step()\n",
    "    #gather loss\n",
    "    cur_loss.append(loss.detach().cpu().numpy())\n",
    "    print(\"epoch \",epoch)\n",
    "    print(\"training loss: \", np.mean(cur_loss))\n",
    "    net.eval()\n",
    "    probs_val = net(test_features_tensor)\n",
    "    loss_val = loss_func(probs_val,test_labels_tensor)\n",
    "    print(\"validation loss: \", np.mean(loss_val.detach().cpu().numpy()))\n",
    "    #Save model if validation is min\n",
    "    if min_validation > np.mean(loss_val.detach().cpu().numpy()):\n",
    "        min_validation = np.mean(loss_val.detach().cpu().numpy())\n",
    "        torch.save(net.state_dict(), './net_parameters_%d.pth' % epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Shallow_Network()\n",
    "checkpoint = torch.load('./net_parameters_147.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_val = model(val_features_tensor)\n",
    "loss_val = loss_func(probs_val,val_labels_tensor)\n",
    "print(\"validation loss: \", np.mean(loss_val.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classification probabilities from hidden state array\n",
    "# And apply Softmax\n",
    "with torch.no_grad():\n",
    "    probs = model(val_features_tensor)\n",
    "    softprobs = F.softmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(softprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most likely class and its index for each sample point\n",
    "values, indices = torch.max(softprobs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted labels\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take original labels\n",
    "labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of sample points where prediction failed\n",
    "nums = torch.sum(torch.abs(val_labels_tensor-indices)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of correct predictions\n",
    "numcorrect = 2000-(nums+0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of prediction\n",
    "accuracy = numcorrect/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.asarray(indices.detach().cpu().numpy())\n",
    "lbls = np.asarray(labels_tensor.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.iloc[np.where(idx-lbls)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using test set\n",
    "probs_test = model(test_features_tensor)\n",
    "loss_test = loss_func(probs_test,test_labels_tensor)\n",
    "print(\"test loss: \", np.mean(loss_test.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    probs_test = model(test_features_tensor)\n",
    "    softprobs_test = F.softmax(probs_test)\n",
    "# Get most likely class and its index for each sample point\n",
    "test_values, test_indices = torch.max(softprobs_test,1)\n",
    "# Calculate number of sample points where prediction failed\n",
    "test_nums = torch.sum(torch.abs(test_labels_tensor-test_indices)).detach().cpu().numpy()\n",
    "# Number of correct predictions\n",
    "numcorrect = test_df.shape[0]-(test_nums+0)\n",
    "# Accuracy of prediction\n",
    "accuracy = numcorrect/test_df.shape[0]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
