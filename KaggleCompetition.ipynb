{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>keyword</td>\n",
       "      <td>location</td>\n",
       "      <td>text</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword  location                                               text  \\\n",
       "0  id  keyword  location                                               text   \n",
       "1   1      NaN       NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "2   4      NaN       NaN             Forest fire near La Ronge Sask. Canada   \n",
       "3   5      NaN       NaN  All residents asked to 'shelter in place' are ...   \n",
       "4   6      NaN       NaN  13,000 people receive #wildfires evacuation or...   \n",
       "\n",
       "   target  \n",
       "0  target  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./data/Kaggle/train.csv',delimiter=',',\\\n",
    "                           names=['id','keyword','location', 'text','target'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0                                               text  target\n",
       "1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "2             Forest fire near La Ronge Sask. Canada       1\n",
       "3  All residents asked to 'shelter in place' are ...       1\n",
       "4  13,000 people receive #wildfires evacuation or...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Id, Keyword, Location\n",
    "dataset = dataset.drop(labels=['id', 'keyword','location'], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(tweet):\n",
    "    # Special characters\n",
    "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
    "    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
    "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n",
    "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
    "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å£3million\", \"3 million\", tweet)\n",
    "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "     \n",
    "    # Remove http\n",
    "    tweet = re.sub(r\"http[^\\s]+\",\"\", tweet)\n",
    "    \n",
    "    # Remove @abc\n",
    "    tweet = re.sub(r\"@[^\\s]+\", \"\", tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first row\n",
    "dataset = dataset.drop(index=0)\n",
    "# Clean data\n",
    "dataset['text_cleaned'] = dataset['text'].apply(lambda s : clean(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()\n",
    "dataset['tokenized'] = dataset['text_cleaned'].apply(tt.tokenize)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = sum(dataset['tokenized'].values,[])\n",
    "wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freDist = nltk.FreqDist(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freDist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Tokenized BERT Embeding and Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_token_list(sample):\n",
    "    # Find the sentence with the max length\n",
    "    max_len = 0\n",
    "    for token_list in sample:\n",
    "        if len(token_list) > max_len:\n",
    "            max_len = len(token_list)\n",
    "    # Adjust every sentence to the same length\n",
    "    padded = np.array([token_list + [0]*(max_len-len(token_list)) for token_list in sample])\n",
    "    return padded, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_sample(sample, model):\n",
    "    # Pad sample data:\n",
    "#     sample = pad_token_list(sample)\n",
    "    # Define mask from data: - 0 token entry     -> padding, set mask entry to 0\n",
    "    #                        - non-0 token entry -> valid word, set mask entry to 1\n",
    "    mask = np.where(sample != 0, 1, 0)\n",
    "    \n",
    "    # Create tensor objects from numpy arrays\n",
    "    input_ids = torch.tensor(sample).long()\n",
    "    attention_mask = torch.tensor(mask).long()\n",
    "\n",
    "    # Use BERT model to get embeddings\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    # Extract [CLS] embedding for each sample as numpy array to be used for classification task\n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    return features, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 4000\n",
    "random_sample = dataset.sample(n=sample_size)\n",
    "random_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3613, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set = dataset.loc[dataset.index.difference(random_sample.index)]\n",
    "val_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_random_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2113, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sample_size = 1500\n",
    "val_random_sample = val_set.sample(n=val_sample_size)\n",
    "val_random_sample.shape\n",
    "test_set = val_set.loc[val_set.index.difference(val_random_sample.index)]\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_tokenized = random_sample['text_cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "#sample_tokenized2 = random_sample2['text_cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "val_random_sample_tokenized = val_random_sample['text_cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "#test_tokenized = test_set['text_cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_padded, sample_len = pad_token_list(sample_tokenized.values)\n",
    "val_padded, val_len = pad_token_list(val_random_sample_tokenized.values)\n",
    "#sample_padded2, sample_len2 = pad_token_list(sample_tokenized2.values)\n",
    "#test_padded, test_len = pad_token_list(test_tokenized.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features, mask = get_embeddings_from_sample(sample_padded, model)\n",
    "val_features, mask = get_embeddings_from_sample(val_padded, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Create cuda device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tensor = torch.tensor(np.asarray(sample_features))\n",
    "train_features_tensor = train_features_tensor.to(device)\n",
    "train_labels_tensor =  torch.tensor(np.asarray(random_sample['target']).astype(np.int))\n",
    "train_labels_tensor = train_labels_tensor.to(device)\n",
    "\n",
    "val_features_tensor = torch.tensor(np.asarray(val_features))\n",
    "val_features_tensor = val_features_tensor.to(device)\n",
    "val_labels_tensor =  torch.tensor(np.asarray(val_random_sample['target']).astype(np.int))\n",
    "val_labels_tensor = val_labels_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network class to be trained\n",
    "# Structure:\n",
    "# input -> fc1 -> sigmoid -> out -> log_softmax\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Shallow_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Shallow_Network,self).__init__()\n",
    "        self.fc1 = nn.Linear(768,1000)\n",
    "        self.out = nn.Linear(1000,2)\n",
    "    def forward(self,input):\n",
    "        # Take input, feed through fc1 layer,\n",
    "        # then apply activation function to it\n",
    "        x = F.sigmoid(self.fc1(input))\n",
    "        # Take output of sigmoid, input into out layer,\n",
    "        # and apply log_softmax function\n",
    "        return (F.log_softmax(self.out(x),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network object\n",
    "net = Shallow_Network()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#Create an stochastic gradient descent optimizer\n",
    "adam = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_func = nn.NLLLoss()\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net,features,labels):\n",
    "    # Get classification probabilities from hidden state array\n",
    "    # And apply Softmax\n",
    "    with torch.no_grad():\n",
    "        probs = net(features)\n",
    "        softprobs = F.softmax(probs)\n",
    "    # Get most likely class and its index for each sample point\n",
    "    values, indices = torch.max(softprobs,1)\n",
    "    # Calculate number of sample points where prediction failed\n",
    "    nums = torch.sum(torch.abs(labels-indices)).detach().cpu().numpy()\n",
    "    # Number of correct predictions\n",
    "    numcorrect = len(labels)-(nums+0)\n",
    "    # Accuracy of prediction\n",
    "    accuracy = numcorrect/len(labels)\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "training loss:  0.71944815\n",
      "validation loss:  0.80657357\n",
      "validation accuracy:  0.5766666666666667\n",
      "epoch  1\n",
      "training loss:  0.77052534\n",
      "validation loss:  0.68252236\n",
      "validation accuracy:  0.5766666666666667\n",
      "epoch  2\n",
      "training loss:  0.7438679\n",
      "validation loss:  0.64430773\n",
      "validation accuracy:  0.7473333333333333\n",
      "epoch  3\n",
      "training loss:  0.7186316\n",
      "validation loss:  0.69184595\n",
      "validation accuracy:  0.42333333333333334\n",
      "epoch  4\n",
      "training loss:  0.71202004\n",
      "validation loss:  0.6555037\n",
      "validation accuracy:  0.494\n",
      "epoch  5\n",
      "training loss:  0.7017092\n",
      "validation loss:  0.5925359\n",
      "validation accuracy:  0.7673333333333333\n",
      "epoch  6\n",
      "training loss:  0.685902\n",
      "validation loss:  0.5764187\n",
      "validation accuracy:  0.708\n",
      "epoch  7\n",
      "training loss:  0.67255175\n",
      "validation loss:  0.58750844\n",
      "validation accuracy:  0.666\n",
      "epoch  8\n",
      "training loss:  0.6636671\n",
      "validation loss:  0.578551\n",
      "validation accuracy:  0.6813333333333333\n",
      "epoch  9\n",
      "training loss:  0.6556619\n",
      "validation loss:  0.5497175\n",
      "validation accuracy:  0.724\n",
      "epoch  10\n",
      "training loss:  0.646321\n",
      "validation loss:  0.5288704\n",
      "validation accuracy:  0.784\n",
      "epoch  11\n",
      "training loss:  0.6365683\n",
      "validation loss:  0.5297325\n",
      "validation accuracy:  0.77\n",
      "epoch  12\n",
      "training loss:  0.62817615\n",
      "validation loss:  0.5364349\n",
      "validation accuracy:  0.758\n",
      "epoch  13\n",
      "training loss:  0.6213458\n",
      "validation loss:  0.5294611\n",
      "validation accuracy:  0.758\n",
      "epoch  14\n",
      "training loss:  0.6149565\n",
      "validation loss:  0.5109977\n",
      "validation accuracy:  0.7733333333333333\n",
      "epoch  15\n",
      "training loss:  0.6082903\n",
      "validation loss:  0.49619603\n",
      "validation accuracy:  0.7846666666666666\n",
      "epoch  16\n",
      "training loss:  0.60164887\n",
      "validation loss:  0.49255472\n",
      "validation accuracy:  0.792\n",
      "epoch  17\n",
      "training loss:  0.59563977\n",
      "validation loss:  0.4938623\n",
      "validation accuracy:  0.788\n",
      "epoch  18\n",
      "training loss:  0.5903853\n",
      "validation loss:  0.4911361\n",
      "validation accuracy:  0.7886666666666666\n",
      "epoch  19\n",
      "training loss:  0.5855225\n",
      "validation loss:  0.48326197\n",
      "validation accuracy:  0.792\n",
      "epoch  20\n",
      "training loss:  0.5807071\n",
      "validation loss:  0.47610202\n",
      "validation accuracy:  0.79\n",
      "epoch  21\n",
      "training loss:  0.57593703\n",
      "validation loss:  0.47452405\n",
      "validation accuracy:  0.7873333333333333\n",
      "epoch  22\n",
      "training loss:  0.5714407\n",
      "validation loss:  0.47679606\n",
      "validation accuracy:  0.782\n",
      "epoch  23\n",
      "training loss:  0.567357\n",
      "validation loss:  0.4771197\n",
      "validation accuracy:  0.7813333333333333\n",
      "epoch  24\n",
      "training loss:  0.5635859\n",
      "validation loss:  0.4726959\n",
      "validation accuracy:  0.786\n",
      "epoch  25\n",
      "training loss:  0.55993944\n",
      "validation loss:  0.46629137\n",
      "validation accuracy:  0.788\n",
      "epoch  26\n",
      "training loss:  0.5563522\n",
      "validation loss:  0.462126\n",
      "validation accuracy:  0.7913333333333333\n",
      "epoch  27\n",
      "training loss:  0.5529045\n",
      "validation loss:  0.46113306\n",
      "validation accuracy:  0.798\n",
      "epoch  28\n",
      "training loss:  0.5496841\n",
      "validation loss:  0.46089572\n",
      "validation accuracy:  0.7986666666666666\n",
      "epoch  29\n",
      "training loss:  0.54667735\n",
      "validation loss:  0.45918962\n",
      "validation accuracy:  0.7986666666666666\n",
      "epoch  30\n",
      "training loss:  0.5437973\n",
      "validation loss:  0.456433\n",
      "validation accuracy:  0.8\n",
      "epoch  31\n",
      "training loss:  0.5409835\n",
      "validation loss:  0.45466644\n",
      "validation accuracy:  0.7986666666666666\n",
      "epoch  32\n",
      "training loss:  0.53825057\n",
      "validation loss:  0.4548103\n",
      "validation accuracy:  0.792\n",
      "epoch  33\n",
      "training loss:  0.5356472\n",
      "validation loss:  0.45549214\n",
      "validation accuracy:  0.792\n",
      "epoch  34\n",
      "training loss:  0.53318596\n",
      "validation loss:  0.45473617\n",
      "validation accuracy:  0.7946666666666666\n",
      "epoch  35\n",
      "training loss:  0.5308279\n",
      "validation loss:  0.4522808\n",
      "validation accuracy:  0.796\n",
      "epoch  36\n",
      "training loss:  0.5285311\n",
      "validation loss:  0.44963244\n",
      "validation accuracy:  0.7953333333333333\n",
      "epoch  37\n",
      "training loss:  0.52629286\n",
      "validation loss:  0.4481082\n",
      "validation accuracy:  0.8\n",
      "epoch  38\n",
      "training loss:  0.52413803\n",
      "validation loss:  0.44751108\n",
      "validation accuracy:  0.8033333333333333\n",
      "epoch  39\n",
      "training loss:  0.5220781\n",
      "validation loss:  0.44683158\n",
      "validation accuracy:  0.802\n",
      "epoch  40\n",
      "training loss:  0.52009547\n",
      "validation loss:  0.44570747\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  41\n",
      "training loss:  0.5181654\n",
      "validation loss:  0.44474995\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  42\n",
      "training loss:  0.5162823\n",
      "validation loss:  0.44453397\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  43\n",
      "training loss:  0.5144584\n",
      "validation loss:  0.44470036\n",
      "validation accuracy:  0.8033333333333333\n",
      "epoch  44\n",
      "training loss:  0.51270133\n",
      "validation loss:  0.4443532\n",
      "validation accuracy:  0.8046666666666666\n",
      "epoch  45\n",
      "training loss:  0.5110018\n",
      "validation loss:  0.44317693\n",
      "validation accuracy:  0.806\n",
      "epoch  46\n",
      "training loss:  0.5093452\n",
      "validation loss:  0.441752\n",
      "validation accuracy:  0.804\n",
      "epoch  47\n",
      "training loss:  0.50772786\n",
      "validation loss:  0.4407481\n",
      "validation accuracy:  0.802\n",
      "epoch  48\n",
      "training loss:  0.5061566\n",
      "validation loss:  0.44018808\n",
      "validation accuracy:  0.802\n",
      "epoch  49\n",
      "training loss:  0.50463504\n",
      "validation loss:  0.43968058\n",
      "validation accuracy:  0.8026666666666666\n",
      "epoch  50\n",
      "training loss:  0.50315666\n",
      "validation loss:  0.4390967\n",
      "validation accuracy:  0.804\n",
      "epoch  51\n",
      "training loss:  0.50171304\n",
      "validation loss:  0.4386949\n",
      "validation accuracy:  0.808\n",
      "epoch  52\n",
      "training loss:  0.500303\n",
      "validation loss:  0.43861604\n",
      "validation accuracy:  0.8066666666666666\n",
      "epoch  53\n",
      "training loss:  0.49893025\n",
      "validation loss:  0.43855944\n",
      "validation accuracy:  0.8053333333333333\n",
      "epoch  54\n",
      "training loss:  0.49759573\n",
      "validation loss:  0.43813407\n",
      "validation accuracy:  0.8073333333333333\n",
      "epoch  55\n",
      "training loss:  0.49629444\n",
      "validation loss:  0.43735945\n",
      "validation accuracy:  0.8073333333333333\n",
      "epoch  56\n",
      "training loss:  0.49502173\n",
      "validation loss:  0.43659732\n",
      "validation accuracy:  0.8086666666666666\n",
      "epoch  57\n",
      "training loss:  0.49377796\n",
      "validation loss:  0.436075\n",
      "validation accuracy:  0.81\n",
      "epoch  58\n",
      "training loss:  0.4925652\n",
      "validation loss:  0.4357063\n",
      "validation accuracy:  0.81\n",
      "epoch  59\n",
      "training loss:  0.4913823\n",
      "validation loss:  0.43536636\n",
      "validation accuracy:  0.81\n",
      "epoch  60\n",
      "training loss:  0.49022558\n",
      "validation loss:  0.4351098\n",
      "validation accuracy:  0.8086666666666666\n",
      "epoch  61\n",
      "training loss:  0.4890931\n",
      "validation loss:  0.43501192\n",
      "validation accuracy:  0.8093333333333333\n",
      "epoch  62\n",
      "training loss:  0.4879857\n",
      "validation loss:  0.43494812\n",
      "validation accuracy:  0.806\n",
      "epoch  63\n",
      "training loss:  0.48690385\n",
      "validation loss:  0.43470398\n",
      "validation accuracy:  0.806\n",
      "epoch  64\n",
      "training loss:  0.48584557\n",
      "validation loss:  0.4342523\n",
      "validation accuracy:  0.808\n",
      "epoch  65\n",
      "training loss:  0.48480865\n",
      "validation loss:  0.4337717\n",
      "validation accuracy:  0.81\n",
      "epoch  66\n",
      "training loss:  0.48379278\n",
      "validation loss:  0.43340483\n",
      "validation accuracy:  0.81\n",
      "epoch  67\n",
      "training loss:  0.4827984\n",
      "validation loss:  0.43313763\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  68\n",
      "training loss:  0.4818248\n",
      "validation loss:  0.4329236\n",
      "validation accuracy:  0.8106666666666666\n",
      "epoch  69\n",
      "training loss:  0.48087016\n",
      "validation loss:  0.43278277\n",
      "validation accuracy:  0.81\n",
      "epoch  70\n",
      "training loss:  0.47993374\n",
      "validation loss:  0.43271613\n",
      "validation accuracy:  0.808\n",
      "epoch  71\n",
      "training loss:  0.4790155\n",
      "validation loss:  0.43262434\n",
      "validation accuracy:  0.8073333333333333\n",
      "epoch  72\n",
      "training loss:  0.47811535\n",
      "validation loss:  0.43240526\n",
      "validation accuracy:  0.808\n",
      "epoch  73\n",
      "training loss:  0.47723204\n",
      "validation loss:  0.43208447\n",
      "validation accuracy:  0.8093333333333333\n",
      "epoch  74\n",
      "training loss:  0.47636464\n",
      "validation loss:  0.43177152\n",
      "validation accuracy:  0.8093333333333333\n",
      "epoch  75\n",
      "training loss:  0.475513\n",
      "validation loss:  0.4315271\n",
      "validation accuracy:  0.8086666666666666\n",
      "epoch  76\n",
      "training loss:  0.474677\n",
      "validation loss:  0.4313424\n",
      "validation accuracy:  0.8073333333333333\n",
      "epoch  77\n",
      "training loss:  0.47385588\n",
      "validation loss:  0.43120927\n",
      "validation accuracy:  0.8086666666666666\n",
      "epoch  78\n",
      "training loss:  0.47304884\n",
      "validation loss:  0.43112725\n",
      "validation accuracy:  0.8093333333333333\n",
      "epoch  79\n",
      "training loss:  0.47225562\n",
      "validation loss:  0.43105164\n",
      "validation accuracy:  0.8093333333333333\n",
      "epoch  80\n",
      "training loss:  0.47147605\n",
      "validation loss:  0.43091106\n",
      "validation accuracy:  0.81\n",
      "epoch  81\n",
      "training loss:  0.47070965\n",
      "validation loss:  0.43069112\n",
      "validation accuracy:  0.81\n",
      "epoch  82\n",
      "training loss:  0.4699557\n",
      "validation loss:  0.43044877\n",
      "validation accuracy:  0.81\n",
      "epoch  83\n",
      "training loss:  0.46921402\n",
      "validation loss:  0.43024027\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  84\n",
      "training loss:  0.46848437\n",
      "validation loss:  0.43007877\n",
      "validation accuracy:  0.8106666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  85\n",
      "training loss:  0.46776637\n",
      "validation loss:  0.4299602\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  86\n",
      "training loss:  0.46705955\n",
      "validation loss:  0.42987663\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  87\n",
      "training loss:  0.46636355\n",
      "validation loss:  0.42979622\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  88\n",
      "training loss:  0.4656783\n",
      "validation loss:  0.42967343\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  89\n",
      "training loss:  0.46500346\n",
      "validation loss:  0.4294975\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  90\n",
      "training loss:  0.46433857\n",
      "validation loss:  0.42930403\n",
      "validation accuracy:  0.812\n",
      "epoch  91\n",
      "training loss:  0.46368346\n",
      "validation loss:  0.42913148\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  92\n",
      "training loss:  0.4630379\n",
      "validation loss:  0.4289933\n",
      "validation accuracy:  0.814\n",
      "epoch  93\n",
      "training loss:  0.46240166\n",
      "validation loss:  0.4288878\n",
      "validation accuracy:  0.8153333333333334\n",
      "epoch  94\n",
      "training loss:  0.46177432\n",
      "validation loss:  0.42880306\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  95\n",
      "training loss:  0.46115577\n",
      "validation loss:  0.4287109\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  96\n",
      "training loss:  0.4605458\n",
      "validation loss:  0.42858404\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  97\n",
      "training loss:  0.45994416\n",
      "validation loss:  0.42842504\n",
      "validation accuracy:  0.812\n",
      "epoch  98\n",
      "training loss:  0.4593506\n",
      "validation loss:  0.42826164\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  99\n",
      "training loss:  0.4587649\n",
      "validation loss:  0.4281174\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  100\n",
      "training loss:  0.45818695\n",
      "validation loss:  0.42799968\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  101\n",
      "training loss:  0.4576165\n",
      "validation loss:  0.42790398\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  102\n",
      "training loss:  0.45705336\n",
      "validation loss:  0.42781368\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  103\n",
      "training loss:  0.45649734\n",
      "validation loss:  0.42770633\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  104\n",
      "training loss:  0.45594832\n",
      "validation loss:  0.42757288\n",
      "validation accuracy:  0.81\n",
      "epoch  105\n",
      "training loss:  0.45540607\n",
      "validation loss:  0.42742634\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  106\n",
      "training loss:  0.4548705\n",
      "validation loss:  0.4272875\n",
      "validation accuracy:  0.812\n",
      "epoch  107\n",
      "training loss:  0.45434138\n",
      "validation loss:  0.42716783\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  108\n",
      "training loss:  0.45381865\n",
      "validation loss:  0.4270672\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  109\n",
      "training loss:  0.4533021\n",
      "validation loss:  0.42697468\n",
      "validation accuracy:  0.812\n",
      "epoch  110\n",
      "training loss:  0.45279154\n",
      "validation loss:  0.42687356\n",
      "validation accuracy:  0.812\n",
      "epoch  111\n",
      "training loss:  0.4522869\n",
      "validation loss:  0.4267537\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  112\n",
      "training loss:  0.45178804\n",
      "validation loss:  0.4266217\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  113\n",
      "training loss:  0.4512948\n",
      "validation loss:  0.42649284\n",
      "validation accuracy:  0.812\n",
      "epoch  114\n",
      "training loss:  0.4508071\n",
      "validation loss:  0.4263783\n",
      "validation accuracy:  0.812\n",
      "epoch  115\n",
      "training loss:  0.45032477\n",
      "validation loss:  0.42627898\n",
      "validation accuracy:  0.812\n",
      "epoch  116\n",
      "training loss:  0.44984773\n",
      "validation loss:  0.42618656\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  117\n",
      "training loss:  0.44937584\n",
      "validation loss:  0.42608818\n",
      "validation accuracy:  0.812\n",
      "epoch  118\n",
      "training loss:  0.44890898\n",
      "validation loss:  0.42597646\n",
      "validation accuracy:  0.812\n",
      "epoch  119\n",
      "training loss:  0.4484471\n",
      "validation loss:  0.42585665\n",
      "validation accuracy:  0.812\n",
      "epoch  120\n",
      "training loss:  0.44799\n",
      "validation loss:  0.4257403\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  121\n",
      "training loss:  0.44753766\n",
      "validation loss:  0.4256359\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  122\n",
      "training loss:  0.44708994\n",
      "validation loss:  0.42554325\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  123\n",
      "training loss:  0.44664675\n",
      "validation loss:  0.42545468\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  124\n",
      "training loss:  0.446208\n",
      "validation loss:  0.4253606\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  125\n",
      "training loss:  0.4457736\n",
      "validation loss:  0.42525718\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  126\n",
      "training loss:  0.44534343\n",
      "validation loss:  0.42515028\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  127\n",
      "training loss:  0.44491744\n",
      "validation loss:  0.42504907\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  128\n",
      "training loss:  0.44449556\n",
      "validation loss:  0.42495826\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  129\n",
      "training loss:  0.44407764\n",
      "validation loss:  0.42487565\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  130\n",
      "training loss:  0.4436637\n",
      "validation loss:  0.42479354\n",
      "validation accuracy:  0.812\n",
      "epoch  131\n",
      "training loss:  0.44325355\n",
      "validation loss:  0.42470565\n",
      "validation accuracy:  0.812\n",
      "epoch  132\n",
      "training loss:  0.44284716\n",
      "validation loss:  0.4246123\n",
      "validation accuracy:  0.812\n",
      "epoch  133\n",
      "training loss:  0.4424445\n",
      "validation loss:  0.4245203\n",
      "validation accuracy:  0.812\n",
      "epoch  134\n",
      "training loss:  0.44204545\n",
      "validation loss:  0.42443568\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  135\n",
      "training loss:  0.44164994\n",
      "validation loss:  0.42435905\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  136\n",
      "training loss:  0.44125792\n",
      "validation loss:  0.42428604\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  137\n",
      "training loss:  0.44086933\n",
      "validation loss:  0.4242104\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  138\n",
      "training loss:  0.44048408\n",
      "validation loss:  0.42413005\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  139\n",
      "training loss:  0.4401021\n",
      "validation loss:  0.42404896\n",
      "validation accuracy:  0.812\n",
      "epoch  140\n",
      "training loss:  0.43972334\n",
      "validation loss:  0.4239726\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  141\n",
      "training loss:  0.43934777\n",
      "validation loss:  0.42390323\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  142\n",
      "training loss:  0.4389753\n",
      "validation loss:  0.42383802\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  143\n",
      "training loss:  0.43860584\n",
      "validation loss:  0.4237718\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  144\n",
      "training loss:  0.4382394\n",
      "validation loss:  0.42370203\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  145\n",
      "training loss:  0.43787587\n",
      "validation loss:  0.4236312\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  146\n",
      "training loss:  0.43751526\n",
      "validation loss:  0.42356375\n",
      "validation accuracy:  0.814\n",
      "epoch  147\n",
      "training loss:  0.43715745\n",
      "validation loss:  0.42350203\n",
      "validation accuracy:  0.814\n",
      "epoch  148\n",
      "training loss:  0.4368024\n",
      "validation loss:  0.42344394\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  149\n",
      "training loss:  0.43645015\n",
      "validation loss:  0.42338547\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  150\n",
      "training loss:  0.43610054\n",
      "validation loss:  0.42332435\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  151\n",
      "training loss:  0.43575352\n",
      "validation loss:  0.4232627\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  152\n",
      "training loss:  0.43540916\n",
      "validation loss:  0.4232041\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  153\n",
      "training loss:  0.43506727\n",
      "validation loss:  0.4231501\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  154\n",
      "training loss:  0.4347279\n",
      "validation loss:  0.42309895\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  155\n",
      "training loss:  0.43439096\n",
      "validation loss:  0.4230474\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  156\n",
      "training loss:  0.43405646\n",
      "validation loss:  0.4229941\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  157\n",
      "training loss:  0.4337243\n",
      "validation loss:  0.4229411\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  158\n",
      "training loss:  0.43339452\n",
      "validation loss:  0.4228912\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  159\n",
      "training loss:  0.43306693\n",
      "validation loss:  0.42284536\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  160\n",
      "training loss:  0.43274167\n",
      "validation loss:  0.4228012\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  161\n",
      "training loss:  0.43241858\n",
      "validation loss:  0.42275646\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  162\n",
      "training loss:  0.43209764\n",
      "validation loss:  0.42271087\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  163\n",
      "training loss:  0.43177888\n",
      "validation loss:  0.42266688\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  164\n",
      "training loss:  0.4314622\n",
      "validation loss:  0.42262614\n",
      "validation accuracy:  0.814\n",
      "epoch  165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.43114758\n",
      "validation loss:  0.4225883\n",
      "validation accuracy:  0.814\n",
      "epoch  166\n",
      "training loss:  0.43083498\n",
      "validation loss:  0.42255148\n",
      "validation accuracy:  0.814\n",
      "epoch  167\n",
      "training loss:  0.43052438\n",
      "validation loss:  0.422514\n",
      "validation accuracy:  0.814\n",
      "epoch  168\n",
      "training loss:  0.4302157\n",
      "validation loss:  0.42247698\n",
      "validation accuracy:  0.814\n",
      "epoch  169\n",
      "training loss:  0.42990902\n",
      "validation loss:  0.42244247\n",
      "validation accuracy:  0.814\n",
      "epoch  170\n",
      "training loss:  0.42960414\n",
      "validation loss:  0.42241114\n",
      "validation accuracy:  0.814\n",
      "epoch  171\n",
      "training loss:  0.42930123\n",
      "validation loss:  0.42238164\n",
      "validation accuracy:  0.8146666666666667\n",
      "epoch  172\n",
      "training loss:  0.42900005\n",
      "validation loss:  0.42235216\n",
      "validation accuracy:  0.8153333333333334\n",
      "epoch  173\n",
      "training loss:  0.42870077\n",
      "validation loss:  0.422323\n",
      "validation accuracy:  0.8153333333333334\n",
      "epoch  174\n",
      "training loss:  0.42840323\n",
      "validation loss:  0.4222957\n",
      "validation accuracy:  0.8146666666666667\n",
      "epoch  175\n",
      "training loss:  0.42810738\n",
      "validation loss:  0.42227137\n",
      "validation accuracy:  0.8146666666666667\n",
      "epoch  176\n",
      "training loss:  0.42781335\n",
      "validation loss:  0.42224923\n",
      "validation accuracy:  0.8146666666666667\n",
      "epoch  177\n",
      "training loss:  0.42752093\n",
      "validation loss:  0.42222792\n",
      "validation accuracy:  0.8153333333333334\n",
      "epoch  178\n",
      "training loss:  0.4272302\n",
      "validation loss:  0.4222068\n",
      "validation accuracy:  0.8153333333333334\n",
      "epoch  179\n",
      "training loss:  0.4269411\n",
      "validation loss:  0.4221875\n",
      "validation accuracy:  0.8153333333333334\n",
      "epoch  180\n",
      "training loss:  0.42665362\n",
      "validation loss:  0.4221708\n",
      "validation accuracy:  0.8153333333333334\n",
      "epoch  181\n",
      "training loss:  0.42636776\n",
      "validation loss:  0.42215645\n",
      "validation accuracy:  0.8153333333333334\n",
      "epoch  182\n",
      "training loss:  0.42608342\n",
      "validation loss:  0.422143\n",
      "validation accuracy:  0.816\n",
      "epoch  183\n",
      "training loss:  0.42580062\n",
      "validation loss:  0.42213032\n",
      "validation accuracy:  0.8166666666666667\n",
      "epoch  184\n",
      "training loss:  0.42551935\n",
      "validation loss:  0.42211917\n",
      "validation accuracy:  0.8166666666666667\n",
      "epoch  185\n",
      "training loss:  0.42523956\n",
      "validation loss:  0.42211065\n",
      "validation accuracy:  0.8166666666666667\n",
      "epoch  186\n",
      "training loss:  0.42496118\n",
      "validation loss:  0.42210418\n",
      "validation accuracy:  0.8166666666666667\n",
      "epoch  187\n",
      "training loss:  0.42468432\n",
      "validation loss:  0.42209896\n",
      "validation accuracy:  0.816\n",
      "epoch  188\n",
      "training loss:  0.42440885\n",
      "validation loss:  0.42209455\n",
      "validation accuracy:  0.816\n",
      "epoch  189\n",
      "training loss:  0.42413482\n",
      "validation loss:  0.42209175\n",
      "validation accuracy:  0.816\n",
      "epoch  190\n",
      "training loss:  0.42386213\n",
      "validation loss:  0.42209148\n",
      "validation accuracy:  0.816\n",
      "epoch  191\n",
      "training loss:  0.4235908\n",
      "validation loss:  0.42209318\n",
      "validation accuracy:  0.816\n",
      "epoch  192\n",
      "training loss:  0.42332086\n",
      "validation loss:  0.42209598\n",
      "validation accuracy:  0.816\n",
      "epoch  193\n",
      "training loss:  0.42305216\n",
      "validation loss:  0.4220998\n",
      "validation accuracy:  0.8153333333333334\n",
      "epoch  194\n",
      "training loss:  0.4227848\n",
      "validation loss:  0.42210552\n",
      "validation accuracy:  0.814\n",
      "epoch  195\n",
      "training loss:  0.42251867\n",
      "validation loss:  0.4221136\n",
      "validation accuracy:  0.814\n",
      "epoch  196\n",
      "training loss:  0.42225385\n",
      "validation loss:  0.4221235\n",
      "validation accuracy:  0.814\n",
      "epoch  197\n",
      "training loss:  0.42199022\n",
      "validation loss:  0.42213455\n",
      "validation accuracy:  0.814\n",
      "epoch  198\n",
      "training loss:  0.42172787\n",
      "validation loss:  0.42214686\n",
      "validation accuracy:  0.8146666666666667\n",
      "epoch  199\n",
      "training loss:  0.4214666\n",
      "validation loss:  0.42216125\n",
      "validation accuracy:  0.814\n",
      "epoch  200\n",
      "training loss:  0.42120662\n",
      "validation loss:  0.42217797\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  201\n",
      "training loss:  0.42094776\n",
      "validation loss:  0.4221961\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  202\n",
      "training loss:  0.4206901\n",
      "validation loss:  0.4222155\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  203\n",
      "training loss:  0.4204335\n",
      "validation loss:  0.42223665\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  204\n",
      "training loss:  0.42017803\n",
      "validation loss:  0.42226017\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  205\n",
      "training loss:  0.4199237\n",
      "validation loss:  0.42228547\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  206\n",
      "training loss:  0.41967043\n",
      "validation loss:  0.42231223\n",
      "validation accuracy:  0.812\n",
      "epoch  207\n",
      "training loss:  0.4194182\n",
      "validation loss:  0.42234048\n",
      "validation accuracy:  0.812\n",
      "epoch  208\n",
      "training loss:  0.41916704\n",
      "validation loss:  0.422371\n",
      "validation accuracy:  0.812\n",
      "epoch  209\n",
      "training loss:  0.41891694\n",
      "validation loss:  0.42240357\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  210\n",
      "training loss:  0.41866782\n",
      "validation loss:  0.4224378\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  211\n",
      "training loss:  0.41841975\n",
      "validation loss:  0.4224734\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  212\n",
      "training loss:  0.41817263\n",
      "validation loss:  0.42251116\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  213\n",
      "training loss:  0.41792655\n",
      "validation loss:  0.42255104\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  214\n",
      "training loss:  0.4176814\n",
      "validation loss:  0.42259264\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  215\n",
      "training loss:  0.41743717\n",
      "validation loss:  0.42263582\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  216\n",
      "training loss:  0.4171939\n",
      "validation loss:  0.42268106\n",
      "validation accuracy:  0.8126666666666666\n",
      "epoch  217\n",
      "training loss:  0.4169515\n",
      "validation loss:  0.42272836\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  218\n",
      "training loss:  0.4167101\n",
      "validation loss:  0.42277753\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  219\n",
      "training loss:  0.41646957\n",
      "validation loss:  0.42282844\n",
      "validation accuracy:  0.8133333333333334\n",
      "epoch  220\n",
      "training loss:  0.41622993\n",
      "validation loss:  0.42288128\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  221\n",
      "training loss:  0.41599116\n",
      "validation loss:  0.42293623\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  222\n",
      "training loss:  0.41575322\n",
      "validation loss:  0.4229931\n",
      "validation accuracy:  0.8106666666666666\n",
      "epoch  223\n",
      "training loss:  0.4155161\n",
      "validation loss:  0.42305169\n",
      "validation accuracy:  0.81\n",
      "epoch  224\n",
      "training loss:  0.41527987\n",
      "validation loss:  0.42311218\n",
      "validation accuracy:  0.81\n",
      "epoch  225\n",
      "training loss:  0.4150445\n",
      "validation loss:  0.4231749\n",
      "validation accuracy:  0.81\n",
      "epoch  226\n",
      "training loss:  0.4148099\n",
      "validation loss:  0.4232395\n",
      "validation accuracy:  0.81\n",
      "epoch  227\n",
      "training loss:  0.41457614\n",
      "validation loss:  0.4233059\n",
      "validation accuracy:  0.8106666666666666\n",
      "epoch  228\n",
      "training loss:  0.41434315\n",
      "validation loss:  0.42337418\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  229\n",
      "training loss:  0.41411093\n",
      "validation loss:  0.42344484\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  230\n",
      "training loss:  0.41387948\n",
      "validation loss:  0.42351717\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  231\n",
      "training loss:  0.41364884\n",
      "validation loss:  0.42359132\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  232\n",
      "training loss:  0.41341892\n",
      "validation loss:  0.42366755\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  233\n",
      "training loss:  0.41318974\n",
      "validation loss:  0.4237459\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  234\n",
      "training loss:  0.41296133\n",
      "validation loss:  0.42382598\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  235\n",
      "training loss:  0.4127336\n",
      "validation loss:  0.4239079\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  236\n",
      "training loss:  0.4125066\n",
      "validation loss:  0.4239921\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  237\n",
      "training loss:  0.41228032\n",
      "validation loss:  0.42407814\n",
      "validation accuracy:  0.8106666666666666\n",
      "epoch  238\n",
      "training loss:  0.41205472\n",
      "validation loss:  0.42416602\n",
      "validation accuracy:  0.81\n",
      "epoch  239\n",
      "training loss:  0.41182986\n",
      "validation loss:  0.42425582\n",
      "validation accuracy:  0.81\n",
      "epoch  240\n",
      "training loss:  0.41160566\n",
      "validation loss:  0.42434773\n",
      "validation accuracy:  0.81\n",
      "epoch  241\n",
      "training loss:  0.41138205\n",
      "validation loss:  0.4244414\n",
      "validation accuracy:  0.8106666666666666\n",
      "epoch  242\n",
      "training loss:  0.4111592\n",
      "validation loss:  0.42453682\n",
      "validation accuracy:  0.812\n",
      "epoch  243\n",
      "training loss:  0.41093698\n",
      "validation loss:  0.42463443\n",
      "validation accuracy:  0.812\n",
      "epoch  244\n",
      "training loss:  0.4107154\n",
      "validation loss:  0.42473382\n",
      "validation accuracy:  0.812\n",
      "epoch  245\n",
      "training loss:  0.41049448\n",
      "validation loss:  0.424835\n",
      "validation accuracy:  0.812\n",
      "epoch  246\n",
      "training loss:  0.41027418\n",
      "validation loss:  0.42493814\n",
      "validation accuracy:  0.812\n",
      "epoch  247\n",
      "training loss:  0.41005448\n",
      "validation loss:  0.42504317\n",
      "validation accuracy:  0.812\n",
      "epoch  248\n",
      "training loss:  0.40983546\n",
      "validation loss:  0.4251499\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  249\n",
      "training loss:  0.409617\n",
      "validation loss:  0.42525846\n",
      "validation accuracy:  0.812\n",
      "epoch  250\n",
      "training loss:  0.40939918\n",
      "validation loss:  0.4253691\n",
      "validation accuracy:  0.812\n",
      "epoch  251\n",
      "training loss:  0.40918192\n",
      "validation loss:  0.42548123\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  252\n",
      "training loss:  0.40896532\n",
      "validation loss:  0.42559528\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  253\n",
      "training loss:  0.40874925\n",
      "validation loss:  0.4257111\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  254\n",
      "training loss:  0.40853378\n",
      "validation loss:  0.4258287\n",
      "validation accuracy:  0.812\n",
      "epoch  255\n",
      "training loss:  0.40831888\n",
      "validation loss:  0.4259479\n",
      "validation accuracy:  0.812\n",
      "epoch  256\n",
      "training loss:  0.40810457\n",
      "validation loss:  0.42606896\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  257\n",
      "training loss:  0.4078908\n",
      "validation loss:  0.42619172\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  258\n",
      "training loss:  0.40767762\n",
      "validation loss:  0.426316\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  259\n",
      "training loss:  0.40746495\n",
      "validation loss:  0.42644218\n",
      "validation accuracy:  0.8106666666666666\n",
      "epoch  260\n",
      "training loss:  0.40725285\n",
      "validation loss:  0.42657\n",
      "validation accuracy:  0.8113333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  261\n",
      "training loss:  0.40704128\n",
      "validation loss:  0.4266993\n",
      "validation accuracy:  0.812\n",
      "epoch  262\n",
      "training loss:  0.40683025\n",
      "validation loss:  0.42683032\n",
      "validation accuracy:  0.812\n",
      "epoch  263\n",
      "training loss:  0.40661973\n",
      "validation loss:  0.42696306\n",
      "validation accuracy:  0.812\n",
      "epoch  264\n",
      "training loss:  0.4064098\n",
      "validation loss:  0.4270972\n",
      "validation accuracy:  0.812\n",
      "epoch  265\n",
      "training loss:  0.40620035\n",
      "validation loss:  0.42723307\n",
      "validation accuracy:  0.812\n",
      "epoch  266\n",
      "training loss:  0.40599144\n",
      "validation loss:  0.42737043\n",
      "validation accuracy:  0.812\n",
      "epoch  267\n",
      "training loss:  0.40578303\n",
      "validation loss:  0.4275093\n",
      "validation accuracy:  0.812\n",
      "epoch  268\n",
      "training loss:  0.4055751\n",
      "validation loss:  0.42764983\n",
      "validation accuracy:  0.812\n",
      "epoch  269\n",
      "training loss:  0.4053677\n",
      "validation loss:  0.42779192\n",
      "validation accuracy:  0.812\n",
      "epoch  270\n",
      "training loss:  0.4051608\n",
      "validation loss:  0.42793533\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  271\n",
      "training loss:  0.4049544\n",
      "validation loss:  0.4280803\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  272\n",
      "training loss:  0.40474853\n",
      "validation loss:  0.42822665\n",
      "validation accuracy:  0.8113333333333334\n",
      "epoch  273\n",
      "training loss:  0.4045431\n",
      "validation loss:  0.42837465\n",
      "validation accuracy:  0.81\n",
      "epoch  274\n",
      "training loss:  0.40433815\n",
      "validation loss:  0.4285239\n",
      "validation accuracy:  0.8093333333333333\n",
      "epoch  275\n",
      "training loss:  0.40413374\n",
      "validation loss:  0.4286746\n",
      "validation accuracy:  0.8093333333333333\n",
      "epoch  276\n",
      "training loss:  0.40392974\n",
      "validation loss:  0.42882687\n",
      "validation accuracy:  0.808\n",
      "epoch  277\n",
      "training loss:  0.40372625\n",
      "validation loss:  0.42898047\n",
      "validation accuracy:  0.808\n",
      "epoch  278\n",
      "training loss:  0.4035232\n",
      "validation loss:  0.42913532\n",
      "validation accuracy:  0.808\n",
      "epoch  279\n",
      "training loss:  0.4033207\n",
      "validation loss:  0.42929167\n",
      "validation accuracy:  0.8086666666666666\n",
      "epoch  280\n",
      "training loss:  0.40311858\n",
      "validation loss:  0.4294493\n",
      "validation accuracy:  0.8086666666666666\n",
      "epoch  281\n",
      "training loss:  0.40291697\n",
      "validation loss:  0.4296084\n",
      "validation accuracy:  0.8086666666666666\n",
      "epoch  282\n",
      "training loss:  0.4027158\n",
      "validation loss:  0.4297686\n",
      "validation accuracy:  0.8086666666666666\n",
      "epoch  283\n",
      "training loss:  0.40251508\n",
      "validation loss:  0.4299302\n",
      "validation accuracy:  0.8093333333333333\n",
      "epoch  284\n",
      "training loss:  0.40231484\n",
      "validation loss:  0.43009317\n",
      "validation accuracy:  0.8086666666666666\n",
      "epoch  285\n",
      "training loss:  0.40211505\n",
      "validation loss:  0.43025735\n",
      "validation accuracy:  0.808\n",
      "epoch  286\n",
      "training loss:  0.4019157\n",
      "validation loss:  0.4304229\n",
      "validation accuracy:  0.8066666666666666\n",
      "epoch  287\n",
      "training loss:  0.4017168\n",
      "validation loss:  0.43058956\n",
      "validation accuracy:  0.806\n",
      "epoch  288\n",
      "training loss:  0.40151834\n",
      "validation loss:  0.43075773\n",
      "validation accuracy:  0.8053333333333333\n",
      "epoch  289\n",
      "training loss:  0.4013203\n",
      "validation loss:  0.43092695\n",
      "validation accuracy:  0.806\n",
      "epoch  290\n",
      "training loss:  0.40112272\n",
      "validation loss:  0.4310975\n",
      "validation accuracy:  0.8053333333333333\n",
      "epoch  291\n",
      "training loss:  0.4009256\n",
      "validation loss:  0.43126914\n",
      "validation accuracy:  0.8053333333333333\n",
      "epoch  292\n",
      "training loss:  0.40072888\n",
      "validation loss:  0.43144214\n",
      "validation accuracy:  0.8053333333333333\n",
      "epoch  293\n",
      "training loss:  0.40053263\n",
      "validation loss:  0.4316163\n",
      "validation accuracy:  0.8046666666666666\n",
      "epoch  294\n",
      "training loss:  0.40033677\n",
      "validation loss:  0.43179166\n",
      "validation accuracy:  0.8046666666666666\n",
      "epoch  295\n",
      "training loss:  0.4001414\n",
      "validation loss:  0.4319681\n",
      "validation accuracy:  0.8053333333333333\n",
      "epoch  296\n",
      "training loss:  0.39994636\n",
      "validation loss:  0.43214607\n",
      "validation accuracy:  0.806\n",
      "epoch  297\n",
      "training loss:  0.3997518\n",
      "validation loss:  0.43232474\n",
      "validation accuracy:  0.806\n",
      "epoch  298\n",
      "training loss:  0.39955768\n",
      "validation loss:  0.43250528\n",
      "validation accuracy:  0.806\n",
      "epoch  299\n",
      "training loss:  0.39936396\n",
      "validation loss:  0.43268576\n",
      "validation accuracy:  0.8053333333333333\n",
      "epoch  300\n",
      "training loss:  0.39917067\n",
      "validation loss:  0.43286982\n",
      "validation accuracy:  0.8053333333333333\n",
      "epoch  301\n",
      "training loss:  0.3989778\n",
      "validation loss:  0.4330503\n",
      "validation accuracy:  0.8046666666666666\n",
      "epoch  302\n",
      "training loss:  0.39878532\n",
      "validation loss:  0.43324116\n",
      "validation accuracy:  0.804\n",
      "epoch  303\n",
      "training loss:  0.39859328\n",
      "validation loss:  0.433415\n",
      "validation accuracy:  0.804\n",
      "epoch  304\n",
      "training loss:  0.39840162\n",
      "validation loss:  0.43362704\n",
      "validation accuracy:  0.804\n",
      "epoch  305\n",
      "training loss:  0.3982104\n",
      "validation loss:  0.43376347\n",
      "validation accuracy:  0.804\n",
      "epoch  306\n",
      "training loss:  0.3980196\n",
      "validation loss:  0.4340682\n",
      "validation accuracy:  0.8033333333333333\n",
      "epoch  307\n",
      "training loss:  0.39782917\n",
      "validation loss:  0.43402553\n",
      "validation accuracy:  0.8033333333333333\n",
      "epoch  308\n",
      "training loss:  0.39763924\n",
      "validation loss:  0.4348218\n",
      "validation accuracy:  0.8053333333333333\n",
      "epoch  309\n",
      "training loss:  0.3974499\n",
      "validation loss:  0.43415263\n",
      "validation accuracy:  0.806\n",
      "epoch  310\n",
      "training loss:  0.39726183\n",
      "validation loss:  0.43668726\n",
      "validation accuracy:  0.8\n",
      "epoch  311\n",
      "training loss:  0.3970757\n",
      "validation loss:  0.43460554\n",
      "validation accuracy:  0.8066666666666666\n",
      "epoch  312\n",
      "training loss:  0.3968902\n",
      "validation loss:  0.4358234\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  313\n",
      "training loss:  0.39670295\n",
      "validation loss:  0.43587425\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  314\n",
      "training loss:  0.39651603\n",
      "validation loss:  0.4351057\n",
      "validation accuracy:  0.8046666666666666\n",
      "epoch  315\n",
      "training loss:  0.39633116\n",
      "validation loss:  0.4367756\n",
      "validation accuracy:  0.8\n",
      "epoch  316\n",
      "training loss:  0.3961459\n",
      "validation loss:  0.43597448\n",
      "validation accuracy:  0.8033333333333333\n",
      "epoch  317\n",
      "training loss:  0.39596015\n",
      "validation loss:  0.43566683\n",
      "validation accuracy:  0.8026666666666666\n",
      "epoch  318\n",
      "training loss:  0.39577594\n",
      "validation loss:  0.437359\n",
      "validation accuracy:  0.8\n",
      "epoch  319\n",
      "training loss:  0.3955922\n",
      "validation loss:  0.43635917\n",
      "validation accuracy:  0.804\n",
      "epoch  320\n",
      "training loss:  0.39540797\n",
      "validation loss:  0.43630213\n",
      "validation accuracy:  0.802\n",
      "epoch  321\n",
      "training loss:  0.39522478\n",
      "validation loss:  0.43784493\n",
      "validation accuracy:  0.7993333333333333\n",
      "epoch  322\n",
      "training loss:  0.39504245\n",
      "validation loss:  0.43684596\n",
      "validation accuracy:  0.8033333333333333\n",
      "epoch  323\n",
      "training loss:  0.39485982\n",
      "validation loss:  0.43699104\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  324\n",
      "training loss:  0.39467782\n",
      "validation loss:  0.43830273\n",
      "validation accuracy:  0.8\n",
      "epoch  325\n",
      "training loss:  0.3944968\n",
      "validation loss:  0.43738326\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  326\n",
      "training loss:  0.39431587\n",
      "validation loss:  0.43772498\n",
      "validation accuracy:  0.804\n",
      "epoch  327\n",
      "training loss:  0.3941352\n",
      "validation loss:  0.43873748\n",
      "validation accuracy:  0.802\n",
      "epoch  328\n",
      "training loss:  0.3939555\n",
      "validation loss:  0.4379535\n",
      "validation accuracy:  0.7986666666666666\n",
      "epoch  329\n",
      "training loss:  0.3937761\n",
      "validation loss:  0.4384939\n",
      "validation accuracy:  0.8033333333333333\n",
      "epoch  330\n",
      "training loss:  0.39359692\n",
      "validation loss:  0.4391416\n",
      "validation accuracy:  0.8033333333333333\n",
      "epoch  331\n",
      "training loss:  0.39341852\n",
      "validation loss:  0.43855053\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  332\n",
      "training loss:  0.39324063\n",
      "validation loss:  0.43927622\n",
      "validation accuracy:  0.8026666666666666\n",
      "epoch  333\n",
      "training loss:  0.39306304\n",
      "validation loss:  0.4395214\n",
      "validation accuracy:  0.8033333333333333\n",
      "epoch  334\n",
      "training loss:  0.3928859\n",
      "validation loss:  0.43918002\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  335\n",
      "training loss:  0.3927095\n",
      "validation loss:  0.44002953\n",
      "validation accuracy:  0.8026666666666666\n",
      "epoch  336\n",
      "training loss:  0.39253342\n",
      "validation loss:  0.43990836\n",
      "validation accuracy:  0.8026666666666666\n",
      "epoch  337\n",
      "training loss:  0.39235774\n",
      "validation loss:  0.4398628\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  338\n",
      "training loss:  0.39218265\n",
      "validation loss:  0.4406915\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  339\n",
      "training loss:  0.39200807\n",
      "validation loss:  0.44034892\n",
      "validation accuracy:  0.802\n",
      "epoch  340\n",
      "training loss:  0.3918339\n",
      "validation loss:  0.44062194\n",
      "validation accuracy:  0.8026666666666666\n",
      "epoch  341\n",
      "training loss:  0.39166015\n",
      "validation loss:  0.44121167\n",
      "validation accuracy:  0.802\n",
      "epoch  342\n",
      "training loss:  0.39148697\n",
      "validation loss:  0.4408792\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  343\n",
      "training loss:  0.39131427\n",
      "validation loss:  0.44143444\n",
      "validation accuracy:  0.8026666666666666\n",
      "epoch  344\n",
      "training loss:  0.39114195\n",
      "validation loss:  0.441616\n",
      "validation accuracy:  0.802\n",
      "epoch  345\n",
      "training loss:  0.39097014\n",
      "validation loss:  0.4415185\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  346\n",
      "training loss:  0.39079884\n",
      "validation loss:  0.4421813\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  347\n",
      "training loss:  0.39062798\n",
      "validation loss:  0.44202292\n",
      "validation accuracy:  0.802\n",
      "epoch  348\n",
      "training loss:  0.39045754\n",
      "validation loss:  0.44227958\n",
      "validation accuracy:  0.802\n",
      "epoch  349\n",
      "training loss:  0.39028755\n",
      "validation loss:  0.442725\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  350\n",
      "training loss:  0.39011812\n",
      "validation loss:  0.44255087\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  351\n",
      "training loss:  0.3899491\n",
      "validation loss:  0.4430892\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  352\n",
      "training loss:  0.38978052\n",
      "validation loss:  0.4431195\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  353\n",
      "training loss:  0.3896124\n",
      "validation loss:  0.44324988\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  354\n",
      "training loss:  0.38944474\n",
      "validation loss:  0.44372243\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  355\n",
      "training loss:  0.38927755\n",
      "validation loss:  0.4435925\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  356\n",
      "training loss:  0.38911083\n",
      "validation loss:  0.4440587\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  357\n",
      "training loss:  0.38894448\n",
      "validation loss:  0.44413063\n",
      "validation accuracy:  0.8\n",
      "epoch  358\n",
      "training loss:  0.3887786\n",
      "validation loss:  0.4442806\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  359\n",
      "training loss:  0.38861313\n",
      "validation loss:  0.44468537\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  360\n",
      "training loss:  0.38844818\n",
      "validation loss:  0.44461593\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  361\n",
      "training loss:  0.38828367\n",
      "validation loss:  0.4450795\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  362\n",
      "training loss:  0.38811952\n",
      "validation loss:  0.44508466\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  363\n",
      "training loss:  0.38795584\n",
      "validation loss:  0.4453613\n",
      "validation accuracy:  0.8\n",
      "epoch  364\n",
      "training loss:  0.38779256\n",
      "validation loss:  0.44560605\n",
      "validation accuracy:  0.7993333333333333\n",
      "epoch  365\n",
      "training loss:  0.38762978\n",
      "validation loss:  0.44566625\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  366\n",
      "training loss:  0.38746735\n",
      "validation loss:  0.44608048\n",
      "validation accuracy:  0.7993333333333333\n",
      "epoch  367\n",
      "training loss:  0.38730538\n",
      "validation loss:  0.44604424\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  368\n",
      "training loss:  0.38714385\n",
      "validation loss:  0.44647354\n",
      "validation accuracy:  0.8\n",
      "epoch  369\n",
      "training loss:  0.38698268\n",
      "validation loss:  0.44647965\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  370\n",
      "training loss:  0.386822\n",
      "validation loss:  0.44681963\n",
      "validation accuracy:  0.7993333333333333\n",
      "epoch  371\n",
      "training loss:  0.38666165\n",
      "validation loss:  0.4469397\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  372\n",
      "training loss:  0.3865017\n",
      "validation loss:  0.44716126\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  373\n",
      "training loss:  0.38634223\n",
      "validation loss:  0.44739848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  0.8013333333333333\n",
      "epoch  374\n",
      "training loss:  0.3861831\n",
      "validation loss:  0.44751567\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  375\n",
      "training loss:  0.38602448\n",
      "validation loss:  0.44784835\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  376\n",
      "training loss:  0.38586617\n",
      "validation loss:  0.44787818\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  377\n",
      "training loss:  0.38570827\n",
      "validation loss:  0.44829985\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  378\n",
      "training loss:  0.3855508\n",
      "validation loss:  0.4482333\n",
      "validation accuracy:  0.8\n",
      "epoch  379\n",
      "training loss:  0.38539374\n",
      "validation loss:  0.44877902\n",
      "validation accuracy:  0.802\n",
      "epoch  380\n",
      "training loss:  0.3852371\n",
      "validation loss:  0.4485594\n",
      "validation accuracy:  0.7986666666666666\n",
      "epoch  381\n",
      "training loss:  0.38508078\n",
      "validation loss:  0.4493394\n",
      "validation accuracy:  0.8\n",
      "epoch  382\n",
      "training loss:  0.38492498\n",
      "validation loss:  0.448832\n",
      "validation accuracy:  0.7993333333333333\n",
      "epoch  383\n",
      "training loss:  0.38476965\n",
      "validation loss:  0.45010713\n",
      "validation accuracy:  0.7986666666666666\n",
      "epoch  384\n",
      "training loss:  0.38461486\n",
      "validation loss:  0.44906798\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  385\n",
      "training loss:  0.3844608\n",
      "validation loss:  0.4513227\n",
      "validation accuracy:  0.796\n",
      "epoch  386\n",
      "training loss:  0.3843077\n",
      "validation loss:  0.449441\n",
      "validation accuracy:  0.7993333333333333\n",
      "epoch  387\n",
      "training loss:  0.38415575\n",
      "validation loss:  0.4526781\n",
      "validation accuracy:  0.7973333333333333\n",
      "epoch  388\n",
      "training loss:  0.3840047\n",
      "validation loss:  0.44985762\n",
      "validation accuracy:  0.7993333333333333\n",
      "epoch  389\n",
      "training loss:  0.38385385\n",
      "validation loss:  0.452001\n",
      "validation accuracy:  0.796\n",
      "epoch  390\n",
      "training loss:  0.38370213\n",
      "validation loss:  0.45051038\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  391\n",
      "training loss:  0.38354975\n",
      "validation loss:  0.45062578\n",
      "validation accuracy:  0.8006666666666666\n",
      "epoch  392\n",
      "training loss:  0.38339788\n",
      "validation loss:  0.45249274\n",
      "validation accuracy:  0.7973333333333333\n",
      "epoch  393\n",
      "training loss:  0.38324723\n",
      "validation loss:  0.45078877\n",
      "validation accuracy:  0.8\n",
      "epoch  394\n",
      "training loss:  0.38309738\n",
      "validation loss:  0.45281836\n",
      "validation accuracy:  0.7973333333333333\n",
      "epoch  395\n",
      "training loss:  0.38294744\n",
      "validation loss:  0.45143026\n",
      "validation accuracy:  0.8026666666666666\n",
      "epoch  396\n",
      "training loss:  0.38279712\n",
      "validation loss:  0.4517533\n",
      "validation accuracy:  0.8013333333333333\n",
      "epoch  397\n",
      "training loss:  0.38264707\n",
      "validation loss:  0.4530529\n",
      "validation accuracy:  0.7966666666666666\n",
      "epoch  398\n",
      "training loss:  0.3824979\n",
      "validation loss:  0.4518014\n",
      "validation accuracy:  0.8\n",
      "epoch  399\n",
      "training loss:  0.38234943\n",
      "validation loss:  0.4535365\n",
      "validation accuracy:  0.7973333333333333\n"
     ]
    }
   ],
   "source": [
    "# Train network\n",
    "cnt = 0\n",
    "average_losses = []\n",
    "average_val_losses = []\n",
    "acc = []\n",
    "cur_loss = []\n",
    "min_validation = 10000.0\n",
    "min_val_epoch = 0\n",
    "for epoch in range(400):\n",
    "    net.train()\n",
    "    #zero the gradient\n",
    "    adam.zero_grad()\n",
    "    #Get output of network\n",
    "    probs = net(train_features_tensor)\n",
    "    #compute loss\n",
    "    loss = loss_func(probs,train_labels_tensor)\n",
    "    #compute the backward gradient and move network in that direction\n",
    "    loss.backward()\n",
    "    adam.step()\n",
    "    #gather loss\n",
    "    cur_loss.append(loss.detach().cpu().numpy())\n",
    "    print(\"epoch \",epoch)\n",
    "    print(\"training loss: \", np.mean(cur_loss))\n",
    "    net.eval()\n",
    "    probs_val = net(val_features_tensor)\n",
    "    loss_val = loss_func(probs_val,val_labels_tensor)\n",
    "    print(\"validation loss: \", np.mean(loss_val.detach().cpu().numpy()))\n",
    "    print(\"validation accuracy: \", accuracy(net,val_features_tensor,val_labels_tensor))\n",
    "    #Save model if validation is min\n",
    "    if min_validation > np.mean(loss_val.detach().cpu().numpy()):\n",
    "        min_validation = np.mean(loss_val.detach().cpu().numpy())\n",
    "        min_val_epoch = epoch\n",
    "        torch.save(net.state_dict(), './net_parameters_kaggle.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Shallow_Network(\n",
       "  (fc1): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  (out): Linear(in_features=1000, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Shallow_Network()\n",
    "checkpoint = torch.load('./net_parameters_kaggle.pth')\n",
    "net.load_state_dict(checkpoint)\n",
    "net = net.to(device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss:  0.42253873\n"
     ]
    }
   ],
   "source": [
    "probs_val = net(val_features_tensor)\n",
    "loss_val = loss_func(probs_val,val_labels_tensor)\n",
    "print(\"validation loss: \", np.mean(loss_val.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(net,val_features_tensor,val_labels_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = val_set.loc[val_set.index.difference(val_random_sample.index)]\n",
    "test_random_sample_tokenized = test_set['text_cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "test_padded, test_len = pad_token_list(test_random_sample_tokenized.values)\n",
    "test_features, mask = get_embeddings_from_sample(test_padded, model)\n",
    "test_features_tensor = torch.tensor(np.asarray(test_features))\n",
    "test_features_tensor = test_features_tensor.to(device)\n",
    "test_labels_tensor =  torch.tensor(np.asarray(test_set['target']).astype(np.int))\n",
    "test_labels_tensor = test_labels_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8187411263606247\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(net,test_features_tensor,test_labels_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline only html tag and special character cleaning yielded 81.8% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
