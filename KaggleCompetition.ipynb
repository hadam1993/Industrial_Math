{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:24.033787Z",
     "start_time": "2020-03-11T15:36:24.018121Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "from pattern.en import spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_lengthening(text):\n",
    "    pattern = re.compile(r\"([a-zA-Z])\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(text):\n",
    "    pattern = re.compile(r\"(\\s)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " asdrfr \n"
     ]
    }
   ],
   "source": [
    "text = \"       asdrfr    \"\n",
    "print(remove_extra_spaces(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lool\n",
      "[('look', 0.7941176470588235), ('fool', 0.07282913165266107), ('wool', 0.058823529411764705), ('pool', 0.036414565826330535), ('cool', 0.015406162464985995), ('tool', 0.00980392156862745), ('loop', 0.0056022408963585435), ('loot', 0.004201680672268907), ('loom', 0.0028011204481792717)]\n"
     ]
    }
   ],
   "source": [
    "from pattern.en import suggest\n",
    "sentence = \"The score has gone finalllllll\"\n",
    "word = \"loool\"\n",
    "word_wlf = reduce_lengthening(word) #calling function defined above\n",
    "print(word_wlf) #word lengthening isn't being able to fix it completely\n",
    "\n",
    "correct_word = suggest(word_wlf) \n",
    "print(correct_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def lemmatize(tweet, nlp):\n",
    "    doc = nlp(tweet)\n",
    "    newSentence = \" \".join([token.lemma_ for token in doc])\n",
    "    return(newSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellCheck(tweet):\n",
    "    tokenz = word_tokenize(tweet)\n",
    "    newSentence = \"\"\n",
    "    for token in tokenz:\n",
    "        correct_word = suggest(token)\n",
    "        newWord = correct_word[0][0]\n",
    "        newSentence += newWord + \" \"\n",
    "    newSentence = newSentence[:-1]\n",
    "    return(newSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordninja\n",
    "def splitWords(tweet):\n",
    "    doc = nlp(tweet)\n",
    "    newSentence = \" \".join([\" \".join(wordninja.split(str(token))) for token in doc])\n",
    "    return(newSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:24.271474Z",
     "start_time": "2020-03-11T15:36:24.255839Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:24.549667Z",
     "start_time": "2020-03-11T15:36:24.487182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id keyword location                                               text  \\\n",
       "1  1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "2  4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "3  5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "4  6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "5  7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "  target  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "5      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./data/Kaggle/train.csv',delimiter=',',\\\n",
    "                           names=['id','keyword','location', 'text','target'])\n",
    "dataset = dataset.drop(0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:24.803454Z",
     "start_time": "2020-03-11T15:36:24.772218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0                                               text  target\n",
       "1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "2             Forest fire near La Ronge Sask. Canada       1\n",
       "3  All residents asked to 'shelter in place' are ...       1\n",
       "4  13,000 people receive #wildfires evacuation or...       1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Id, Keyword, Location\n",
    "dataset = dataset.drop(labels=['id', 'keyword','location'], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:25.088310Z",
     "start_time": "2020-03-11T15:36:25.057042Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "#from string import maketrans\n",
    "def clean(tweet,nlp):\n",
    "    # Special characters\n",
    "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
    "    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
    "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n",
    "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
    "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å£3million\", \"3 million\", tweet)\n",
    "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"amp\", \"and\", tweet)\n",
    "    tweet = re.sub(r\"\\n\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\r\", \"\", tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = reduce_lengthening(tweet)\n",
    "    \n",
    "    tweet = re.sub(r\"x\\d+\", \"\", tweet) \n",
    "    tweet = re.sub(r\"\\d\", \"\", tweet) \n",
    "    tweet = re.sub(r\"\\u0089ã¢\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\s{2,}\", \" \", tweet)\n",
    "    # Remove http\n",
    "    tweet = re.sub(r\"http[^\\s]+\",\"\", tweet)\n",
    "    tweet = re.sub(r\"http\",\"\", tweet)\n",
    "    tweet = re.sub(r\"youtube\",\"\", tweet)\n",
    "    # Remove @abc\n",
    "    tweet = re.sub(r\"@[^\\s]+\", \"\", tweet)\n",
    "    tweet = tweet.translate(str.maketrans('','',string.punctuation))\n",
    "    tweet = lemmatize(tweet,nlp)\n",
    "    tweet = remove_extra_spaces(tweet)\n",
    "    tweet = re.sub(r\"^\\s+\",\"\", tweet)\n",
    "    tweet = splitWords(tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:25.986158Z",
     "start_time": "2020-03-11T15:36:25.717663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop first row\n",
    "dataset = dataset.drop(index=0)\n",
    "# Clean data\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "dataset['text_cleaned'] = dataset['text'].apply(lambda s : clean(s,nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:30.138694Z",
     "start_time": "2020-03-11T15:36:30.107654Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>PRON deed be the reason of this earthquake may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la rong e s ask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all resident ask to shelter in place be be not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order in ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just get send this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text target  \\\n",
       "1  Our Deeds are the Reason of this #earthquake M...      1   \n",
       "2             Forest fire near La Ronge Sask. Canada      1   \n",
       "3  All residents asked to 'shelter in place' are ...      1   \n",
       "4  13,000 people receive #wildfires evacuation or...      1   \n",
       "5  Just got sent this photo from Ruby #Alaska as ...      1   \n",
       "\n",
       "                                        text_cleaned  \n",
       "1  PRON deed be the reason of this earthquake may...  \n",
       "2            forest fire near la rong e s ask canada  \n",
       "3  all resident ask to shelter in place be be not...  \n",
       "4  people receive wildfire evacuation order in ca...  \n",
       "5  just get send this photo from ruby alaska as s...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text_cleaned'] = dataset['text_cleaned'].drop_duplicates()\n",
    "dataset['text_cleaned'].replace('', np.nan, inplace=True)\n",
    "dataset.dropna(subset=['text_cleaned'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>PRON deed be the reason of this earthquake may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la rong e s ask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all resident ask to shelter in place be be not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order in ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just get send this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text target  \\\n",
       "1  Our Deeds are the Reason of this #earthquake M...      1   \n",
       "2             Forest fire near La Ronge Sask. Canada      1   \n",
       "3  All residents asked to 'shelter in place' are ...      1   \n",
       "4  13,000 people receive #wildfires evacuation or...      1   \n",
       "5  Just got sent this photo from Ruby #Alaska as ...      1   \n",
       "\n",
       "                                        text_cleaned  \n",
       "1  PRON deed be the reason of this earthquake may...  \n",
       "2            forest fire near la rong e s ask canada  \n",
       "3  all resident ask to shelter in place be be not...  \n",
       "4  people receive wildfire evacuation order in ca...  \n",
       "5  just get send this photo from ruby alaska as s...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:30.639226Z",
     "start_time": "2020-03-11T15:36:30.569988Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['text_cleaned'].to_csv(\"dataset_cleaned2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()\n",
    "dataset['tokenized'] = dataset['text_cleaned'].apply(tt.tokenize)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = sum(dataset['tokenized'].values,[])\n",
    "wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freDist = nltk.FreqDist(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freDist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Tokenized BERT Embeding and Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_token_list(sample):\n",
    "    # Find the sentence with the max length\n",
    "    max_len = 0\n",
    "    for token_list in sample:\n",
    "        if len(token_list) > max_len:\n",
    "            max_len = len(token_list)\n",
    "    # Adjust every sentence to the same length\n",
    "    padded = np.array([token_list + [0]*(max_len-len(token_list)) for token_list in sample])\n",
    "    return padded, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_from_sample(sample, model):\n",
    "    # Pad sample data:\n",
    "#     sample = pad_token_list(sample)\n",
    "    # Define mask from data: - 0 token entry     -> padding, set mask entry to 0\n",
    "    #                        - non-0 token entry -> valid word, set mask entry to 1\n",
    "    mask = np.where(sample != 0, 1, 0)\n",
    "    \n",
    "    # Create tensor objects from numpy arrays\n",
    "    input_ids = torch.tensor(sample).long()\n",
    "    attention_mask = torch.tensor(mask).long()\n",
    "\n",
    "    # Use BERT model to get embeddings\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    # Extract [CLS] embedding for each sample as numpy array to be used for classification task\n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    return features, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset = pd.read_csv('dataset_cleaned2.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PRON deed be the reason of this earthquake may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>forest fire near la rong e s ask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>all resident ask to shelter in place be be not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>people receive wildfire evacuation order in ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>just get send this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  1  PRON deed be the reason of this earthquake may...\n",
       "1  2            forest fire near la rong e s ask canada\n",
       "2  3  all resident ask to shelter in place be be not...\n",
       "3  4  people receive wildfire evacuation order in ca...\n",
       "4  5  just get send this photo from ruby alaska as s..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset.head()\n",
    "#clean_dataset['target'] = dataset.loc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                          1\n",
       "keyword                                                   NaN\n",
       "location                                                  NaN\n",
       "text        Our Deeds are the Reason of this #earthquake M...\n",
       "target                                                      1\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset['target'] = dataset['target'].loc[clean_dataset[0]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PRON deed be the reason of this earthquake may...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>forest fire near la rong e s ask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>all resident ask to shelter in place be be not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>people receive wildfire evacuation order in ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>just get send this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                       text_cleaned target\n",
       "0   1  PRON deed be the reason of this earthquake may...      1\n",
       "1   2            forest fire near la rong e s ask canada      1\n",
       "2   3  all resident ask to shelter in place be be not...      1\n",
       "3   4  people receive wildfire evacuation order in ca...      1\n",
       "4   5  just get send this photo from ruby alaska as s...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = clean_dataset\n",
    "dataset.columns = ['ID','text_cleaned','target']\n",
    "#clean_dataset[0]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 4000\n",
    "random_sample = dataset.sample(n=sample_size)\n",
    "random_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2835, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set = dataset.loc[dataset.index.difference(random_sample.index)]\n",
    "val_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1335, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sample_size = 1500\n",
    "val_random_sample = val_set.sample(n=val_sample_size)\n",
    "val_random_sample.shape\n",
    "test_set = val_set.loc[val_set.index.difference(val_random_sample.index)]\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_tokenized = random_sample['text_cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "#sample_tokenized2 = random_sample2['text_cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "val_random_sample_tokenized = val_random_sample['text_cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "#test_tokenized = test_set['text_cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_padded, sample_len = pad_token_list(sample_tokenized.values)\n",
    "val_padded, val_len = pad_token_list(val_random_sample_tokenized.values)\n",
    "#sample_padded2, sample_len2 = pad_token_list(sample_tokenized2.values)\n",
    "#test_padded, test_len = pad_token_list(test_tokenized.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features, mask = get_embeddings_from_sample(sample_padded, model)\n",
    "val_features, mask = get_embeddings_from_sample(val_padded, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Create cuda device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tensor = torch.tensor(np.asarray(sample_features))\n",
    "train_features_tensor = train_features_tensor.to(device)\n",
    "train_labels_tensor =  torch.FloatTensor(np.asarray(random_sample['target']).astype(np.float))\n",
    "train_labels_tensor = train_labels_tensor.to(device)\n",
    "\n",
    "val_features_tensor = torch.tensor(np.asarray(val_features))\n",
    "val_features_tensor = val_features_tensor.to(device)\n",
    "val_labels_tensor =  torch.FloatTensor(np.asarray(val_random_sample['target']).astype(np.float))\n",
    "val_labels_tensor = val_labels_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network class to be trained\n",
    "# Structure:\n",
    "# input -> fc1 -> sigmoid -> out -> log_softmax\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Shallow_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Shallow_Network,self).__init__()\n",
    "        self.fc1 = nn.Linear(768,1000)\n",
    "        self.out = nn.Linear(1000,2)\n",
    "    def forward(self,input):\n",
    "        # Take input, feed through fc1 layer,\n",
    "        # then apply activation function to it\n",
    "        x = F.sigmoid(self.fc1(input))\n",
    "        # Take output of sigmoid, input into out layer,\n",
    "        # and apply log_softmax function\n",
    "        return (F.log_softmax(self.out(x),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Medium_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Medium_Network,self).__init__()\n",
    "        self.fc1 = nn.Linear(768,1000)\n",
    "        self.fc2 = nn.Linear(1000,5000)\n",
    "        self.fc3 = nn.Linear(5000,1000)\n",
    "        self.out = nn.Linear(1000,1)\n",
    "    def forward(self,input):\n",
    "        # Take input, feed through fc1 layer,\n",
    "        # then apply activation function to it\n",
    "        x = F.relu(self.fc1(input))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.sigmoid(self.out(x))\n",
    "        return(x)\n",
    "        # Take output of sigmoid, input into out layer,\n",
    "        # and apply log_softmax function\n",
    "        #return (F.log_softmax(self.out(x),dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network object\n",
    "#net = Shallow_Network()\n",
    "net = Medium_Network()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#Create an stochastic gradient descent optimizer\n",
    "adam = optim.Adam(net.parameters(), lr=0.001)\n",
    "#loss_func = nn.NLLLoss()\n",
    "loss_func = nn.BCELoss()\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net,features,labels):\n",
    "    # Get classification probabilities from hidden state array\n",
    "    # And apply Softmax\n",
    "    with torch.no_grad():\n",
    "        probs = net(features)\n",
    "        #softprobs = F.softmax(probs)\n",
    "    # Get most likely class and its index for each sample point\n",
    "    #values, indices = torch.max(softprobs,1)\n",
    "    values = torch.round(probs)\n",
    "    # Calculate number of sample points where prediction failed\n",
    "    #nums = torch.sum(torch.abs(labels-indices)).detach().cpu().numpy()\n",
    "    nums = torch.sum(torch.abs(torch.t(torch.round(probs)) - labels))\n",
    "    #nums = torch.sum(torch.abs(labels-values)).detach().cpu().numpy()\n",
    "    # Number of correct predictions\n",
    "    numcorrect = len(labels)-(nums+0)\n",
    "    # Accuracy of prediction\n",
    "    accuracy = numcorrect/len(labels)\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "training loss:  0.69556385\n",
      "validation loss:  0.79055023\n",
      "validation accuracy:  tensor(0.5940, device='cuda:0')\n",
      "epoch  1\n",
      "training loss:  0.74694085\n",
      "validation loss:  0.73043406\n",
      "validation accuracy:  tensor(0.4060, device='cuda:0')\n",
      "epoch  2\n",
      "training loss:  0.74040556\n",
      "validation loss:  0.70251614\n",
      "validation accuracy:  tensor(0.4060, device='cuda:0')\n",
      "epoch  3\n",
      "training loss:  0.73011845\n",
      "validation loss:  0.66950536\n",
      "validation accuracy:  tensor(0.4080, device='cuda:0')\n",
      "epoch  4\n",
      "training loss:  0.7170331\n",
      "validation loss:  0.6426097\n",
      "validation accuracy:  tensor(0.6567, device='cuda:0')\n",
      "epoch  5\n",
      "training loss:  0.70324403\n",
      "validation loss:  0.6124698\n",
      "validation accuracy:  tensor(0.7280, device='cuda:0')\n",
      "epoch  6\n",
      "training loss:  0.68877107\n",
      "validation loss:  0.58187103\n",
      "validation accuracy:  tensor(0.7633, device='cuda:0')\n",
      "epoch  7\n",
      "training loss:  0.6741551\n",
      "validation loss:  0.5540282\n",
      "validation accuracy:  tensor(0.7747, device='cuda:0')\n",
      "epoch  8\n",
      "training loss:  0.6596357\n",
      "validation loss:  0.525295\n",
      "validation accuracy:  tensor(0.7660, device='cuda:0')\n",
      "epoch  9\n",
      "training loss:  0.6450989\n",
      "validation loss:  0.50711465\n",
      "validation accuracy:  tensor(0.7713, device='cuda:0')\n",
      "epoch  10\n",
      "training loss:  0.63109833\n",
      "validation loss:  0.5070799\n",
      "validation accuracy:  tensor(0.7767, device='cuda:0')\n",
      "epoch  11\n",
      "training loss:  0.6186428\n",
      "validation loss:  0.52614415\n",
      "validation accuracy:  tensor(0.7707, device='cuda:0')\n",
      "epoch  12\n",
      "training loss:  0.60965943\n",
      "validation loss:  0.5537336\n",
      "validation accuracy:  tensor(0.7440, device='cuda:0')\n",
      "epoch  13\n",
      "training loss:  0.60381275\n",
      "validation loss:  0.47735617\n",
      "validation accuracy:  tensor(0.7780, device='cuda:0')\n",
      "epoch  14\n",
      "training loss:  0.59375095\n",
      "validation loss:  0.5140288\n",
      "validation accuracy:  tensor(0.7700, device='cuda:0')\n",
      "epoch  15\n",
      "training loss:  0.58730835\n",
      "validation loss:  0.46372983\n",
      "validation accuracy:  tensor(0.7853, device='cuda:0')\n",
      "epoch  16\n",
      "training loss:  0.57872444\n",
      "validation loss:  0.49956787\n",
      "validation accuracy:  tensor(0.7653, device='cuda:0')\n",
      "epoch  17\n",
      "training loss:  0.573122\n",
      "validation loss:  0.46981496\n",
      "validation accuracy:  tensor(0.7833, device='cuda:0')\n",
      "epoch  18\n",
      "training loss:  0.56649464\n",
      "validation loss:  0.4698281\n",
      "validation accuracy:  tensor(0.7820, device='cuda:0')\n",
      "epoch  19\n",
      "training loss:  0.560429\n",
      "validation loss:  0.48347953\n",
      "validation accuracy:  tensor(0.7820, device='cuda:0')\n",
      "epoch  20\n",
      "training loss:  0.55551356\n",
      "validation loss:  0.4610758\n",
      "validation accuracy:  tensor(0.7860, device='cuda:0')\n",
      "epoch  21\n",
      "training loss:  0.5499658\n",
      "validation loss:  0.46553645\n",
      "validation accuracy:  tensor(0.7800, device='cuda:0')\n",
      "epoch  22\n",
      "training loss:  0.54504526\n",
      "validation loss:  0.4718352\n",
      "validation accuracy:  tensor(0.7813, device='cuda:0')\n",
      "epoch  23\n",
      "training loss:  0.54073495\n",
      "validation loss:  0.45723116\n",
      "validation accuracy:  tensor(0.7867, device='cuda:0')\n",
      "epoch  24\n",
      "training loss:  0.53609324\n",
      "validation loss:  0.46623054\n",
      "validation accuracy:  tensor(0.7860, device='cuda:0')\n",
      "epoch  25\n",
      "training loss:  0.53208995\n",
      "validation loss:  0.46619087\n",
      "validation accuracy:  tensor(0.7880, device='cuda:0')\n",
      "epoch  26\n",
      "training loss:  0.52833676\n",
      "validation loss:  0.45524886\n",
      "validation accuracy:  tensor(0.7880, device='cuda:0')\n",
      "epoch  27\n",
      "training loss:  0.5244284\n",
      "validation loss:  0.4601884\n",
      "validation accuracy:  tensor(0.7840, device='cuda:0')\n",
      "epoch  28\n",
      "training loss:  0.52095443\n",
      "validation loss:  0.45925522\n",
      "validation accuracy:  tensor(0.7847, device='cuda:0')\n",
      "epoch  29\n",
      "training loss:  0.51764923\n",
      "validation loss:  0.45302245\n",
      "validation accuracy:  tensor(0.7900, device='cuda:0')\n",
      "epoch  30\n",
      "training loss:  0.51429796\n",
      "validation loss:  0.45896152\n",
      "validation accuracy:  tensor(0.7920, device='cuda:0')\n",
      "epoch  31\n",
      "training loss:  0.5112845\n",
      "validation loss:  0.45706132\n",
      "validation accuracy:  tensor(0.7927, device='cuda:0')\n",
      "epoch  32\n",
      "training loss:  0.5083316\n",
      "validation loss:  0.45338917\n",
      "validation accuracy:  tensor(0.7867, device='cuda:0')\n",
      "epoch  33\n",
      "training loss:  0.505396\n",
      "validation loss:  0.45756376\n",
      "validation accuracy:  tensor(0.7787, device='cuda:0')\n",
      "epoch  34\n",
      "training loss:  0.5026971\n",
      "validation loss:  0.45491248\n",
      "validation accuracy:  tensor(0.7860, device='cuda:0')\n",
      "epoch  35\n",
      "training loss:  0.49998343\n",
      "validation loss:  0.45704508\n",
      "validation accuracy:  tensor(0.7933, device='cuda:0')\n",
      "epoch  36\n",
      "training loss:  0.49738395\n",
      "validation loss:  0.45862606\n",
      "validation accuracy:  tensor(0.7927, device='cuda:0')\n",
      "epoch  37\n",
      "training loss:  0.49490678\n",
      "validation loss:  0.45451915\n",
      "validation accuracy:  tensor(0.7933, device='cuda:0')\n",
      "epoch  38\n",
      "training loss:  0.49242333\n",
      "validation loss:  0.4563319\n",
      "validation accuracy:  tensor(0.7893, device='cuda:0')\n",
      "epoch  39\n",
      "training loss:  0.49009013\n",
      "validation loss:  0.4540653\n",
      "validation accuracy:  tensor(0.7887, device='cuda:0')\n",
      "epoch  40\n",
      "training loss:  0.48775598\n",
      "validation loss:  0.45610127\n",
      "validation accuracy:  tensor(0.7900, device='cuda:0')\n",
      "epoch  41\n",
      "training loss:  0.48550832\n",
      "validation loss:  0.45561263\n",
      "validation accuracy:  tensor(0.7913, device='cuda:0')\n",
      "epoch  42\n",
      "training loss:  0.48329017\n",
      "validation loss:  0.45479825\n",
      "validation accuracy:  tensor(0.7867, device='cuda:0')\n",
      "epoch  43\n",
      "training loss:  0.48110178\n",
      "validation loss:  0.45606306\n",
      "validation accuracy:  tensor(0.7913, device='cuda:0')\n",
      "epoch  44\n",
      "training loss:  0.47896948\n",
      "validation loss:  0.45634913\n",
      "validation accuracy:  tensor(0.7927, device='cuda:0')\n",
      "epoch  45\n",
      "training loss:  0.4768503\n",
      "validation loss:  0.45673075\n",
      "validation accuracy:  tensor(0.7920, device='cuda:0')\n",
      "epoch  46\n",
      "training loss:  0.47476575\n",
      "validation loss:  0.45488602\n",
      "validation accuracy:  tensor(0.7927, device='cuda:0')\n",
      "epoch  47\n",
      "training loss:  0.47269678\n",
      "validation loss:  0.4548889\n",
      "validation accuracy:  tensor(0.7940, device='cuda:0')\n",
      "epoch  48\n",
      "training loss:  0.47064462\n",
      "validation loss:  0.45713496\n",
      "validation accuracy:  tensor(0.7960, device='cuda:0')\n",
      "epoch  49\n",
      "training loss:  0.4686199\n",
      "validation loss:  0.4563325\n",
      "validation accuracy:  tensor(0.7973, device='cuda:0')\n",
      "epoch  50\n",
      "training loss:  0.4665693\n",
      "validation loss:  0.45837528\n",
      "validation accuracy:  tensor(0.7927, device='cuda:0')\n",
      "epoch  51\n",
      "training loss:  0.4645416\n",
      "validation loss:  0.45996216\n",
      "validation accuracy:  tensor(0.7980, device='cuda:0')\n",
      "epoch  52\n",
      "training loss:  0.46251437\n",
      "validation loss:  0.45839688\n",
      "validation accuracy:  tensor(0.7947, device='cuda:0')\n",
      "epoch  53\n",
      "training loss:  0.46045265\n",
      "validation loss:  0.45842057\n",
      "validation accuracy:  tensor(0.7967, device='cuda:0')\n",
      "epoch  54\n",
      "training loss:  0.458375\n",
      "validation loss:  0.46032137\n",
      "validation accuracy:  tensor(0.7953, device='cuda:0')\n",
      "epoch  55\n",
      "training loss:  0.45629278\n",
      "validation loss:  0.46506205\n",
      "validation accuracy:  tensor(0.7887, device='cuda:0')\n",
      "epoch  56\n",
      "training loss:  0.4542458\n",
      "validation loss:  0.4767369\n",
      "validation accuracy:  tensor(0.7960, device='cuda:0')\n",
      "epoch  57\n",
      "training loss:  0.45239955\n",
      "validation loss:  0.49233422\n",
      "validation accuracy:  tensor(0.7787, device='cuda:0')\n",
      "epoch  58\n",
      "training loss:  0.4507751\n",
      "validation loss:  0.4815614\n",
      "validation accuracy:  tensor(0.7913, device='cuda:0')\n",
      "epoch  59\n",
      "training loss:  0.4490282\n",
      "validation loss:  0.45945272\n",
      "validation accuracy:  tensor(0.7993, device='cuda:0')\n",
      "epoch  60\n",
      "training loss:  0.4468734\n",
      "validation loss:  0.491706\n",
      "validation accuracy:  tensor(0.7847, device='cuda:0')\n",
      "epoch  61\n",
      "training loss:  0.44519132\n",
      "validation loss:  0.47572207\n",
      "validation accuracy:  tensor(0.7940, device='cuda:0')\n",
      "epoch  62\n",
      "training loss:  0.44333416\n",
      "validation loss:  0.46480513\n",
      "validation accuracy:  tensor(0.8020, device='cuda:0')\n",
      "epoch  63\n",
      "training loss:  0.4412288\n",
      "validation loss:  0.5005751\n",
      "validation accuracy:  tensor(0.7820, device='cuda:0')\n",
      "epoch  64\n",
      "training loss:  0.43956766\n",
      "validation loss:  0.47355616\n",
      "validation accuracy:  tensor(0.7967, device='cuda:0')\n",
      "epoch  65\n",
      "training loss:  0.43754694\n",
      "validation loss:  0.47158688\n",
      "validation accuracy:  tensor(0.8007, device='cuda:0')\n",
      "epoch  66\n",
      "training loss:  0.43544045\n",
      "validation loss:  0.50590247\n",
      "validation accuracy:  tensor(0.7807, device='cuda:0')\n",
      "epoch  67\n",
      "training loss:  0.43367216\n",
      "validation loss:  0.4774797\n",
      "validation accuracy:  tensor(0.7980, device='cuda:0')\n",
      "epoch  68\n",
      "training loss:  0.43154997\n",
      "validation loss:  0.47813207\n",
      "validation accuracy:  tensor(0.8000, device='cuda:0')\n",
      "epoch  69\n",
      "training loss:  0.4293623\n",
      "validation loss:  0.513331\n",
      "validation accuracy:  tensor(0.7807, device='cuda:0')\n",
      "epoch  70\n",
      "training loss:  0.42747584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss:  0.49185696\n",
      "validation accuracy:  tensor(0.7927, device='cuda:0')\n",
      "epoch  71\n",
      "training loss:  0.42536628\n",
      "validation loss:  0.4850141\n",
      "validation accuracy:  tensor(0.8000, device='cuda:0')\n",
      "epoch  72\n",
      "training loss:  0.4230314\n",
      "validation loss:  0.5238317\n",
      "validation accuracy:  tensor(0.7787, device='cuda:0')\n",
      "epoch  73\n",
      "training loss:  0.42104468\n",
      "validation loss:  0.5232992\n",
      "validation accuracy:  tensor(0.7893, device='cuda:0')\n",
      "epoch  74\n",
      "training loss:  0.4191619\n",
      "validation loss:  0.4994506\n",
      "validation accuracy:  tensor(0.7933, device='cuda:0')\n",
      "epoch  75\n",
      "training loss:  0.41676024\n",
      "validation loss:  0.52637297\n",
      "validation accuracy:  tensor(0.7860, device='cuda:0')\n",
      "epoch  76\n",
      "training loss:  0.41459396\n",
      "validation loss:  0.5415434\n",
      "validation accuracy:  tensor(0.7860, device='cuda:0')\n",
      "epoch  77\n",
      "training loss:  0.41278946\n",
      "validation loss:  0.5178068\n",
      "validation accuracy:  tensor(0.7880, device='cuda:0')\n",
      "epoch  78\n",
      "training loss:  0.41039214\n",
      "validation loss:  0.5357167\n",
      "validation accuracy:  tensor(0.7833, device='cuda:0')\n",
      "epoch  79\n",
      "training loss:  0.40809116\n",
      "validation loss:  0.559914\n",
      "validation accuracy:  tensor(0.7853, device='cuda:0')\n",
      "epoch  80\n",
      "training loss:  0.40624017\n",
      "validation loss:  0.5441561\n",
      "validation accuracy:  tensor(0.7813, device='cuda:0')\n",
      "epoch  81\n",
      "training loss:  0.40385038\n",
      "validation loss:  0.54290664\n",
      "validation accuracy:  tensor(0.7853, device='cuda:0')\n",
      "epoch  82\n",
      "training loss:  0.40138984\n",
      "validation loss:  0.5630621\n",
      "validation accuracy:  tensor(0.7900, device='cuda:0')\n",
      "epoch  83\n",
      "training loss:  0.39929947\n",
      "validation loss:  0.57236654\n",
      "validation accuracy:  tensor(0.7687, device='cuda:0')\n",
      "epoch  84\n",
      "training loss:  0.39693817\n",
      "validation loss:  0.55185354\n",
      "validation accuracy:  tensor(0.7927, device='cuda:0')\n",
      "epoch  85\n",
      "training loss:  0.3943555\n",
      "validation loss:  0.5645149\n",
      "validation accuracy:  tensor(0.7847, device='cuda:0')\n",
      "epoch  86\n",
      "training loss:  0.39182875\n",
      "validation loss:  0.61033404\n",
      "validation accuracy:  tensor(0.7653, device='cuda:0')\n",
      "epoch  87\n",
      "training loss:  0.38944724\n",
      "validation loss:  0.6193896\n",
      "validation accuracy:  tensor(0.7807, device='cuda:0')\n",
      "epoch  88\n",
      "training loss:  0.3873081\n",
      "validation loss:  0.64412355\n",
      "validation accuracy:  tensor(0.7633, device='cuda:0')\n",
      "epoch  89\n",
      "training loss:  0.38495344\n",
      "validation loss:  0.6034327\n",
      "validation accuracy:  tensor(0.7827, device='cuda:0')\n",
      "epoch  90\n",
      "training loss:  0.38241744\n",
      "validation loss:  0.6044566\n",
      "validation accuracy:  tensor(0.7853, device='cuda:0')\n",
      "epoch  91\n",
      "training loss:  0.37974444\n",
      "validation loss:  0.6468391\n",
      "validation accuracy:  tensor(0.7687, device='cuda:0')\n",
      "epoch  92\n",
      "training loss:  0.37725025\n",
      "validation loss:  0.67725587\n",
      "validation accuracy:  tensor(0.7773, device='cuda:0')\n",
      "epoch  93\n",
      "training loss:  0.37515685\n",
      "validation loss:  0.74211013\n",
      "validation accuracy:  tensor(0.7460, device='cuda:0')\n",
      "epoch  94\n",
      "training loss:  0.37300482\n",
      "validation loss:  0.68933624\n",
      "validation accuracy:  tensor(0.7773, device='cuda:0')\n",
      "epoch  95\n",
      "training loss:  0.37083635\n",
      "validation loss:  0.6549642\n",
      "validation accuracy:  tensor(0.7760, device='cuda:0')\n",
      "epoch  96\n",
      "training loss:  0.3681527\n",
      "validation loss:  0.7402938\n",
      "validation accuracy:  tensor(0.7473, device='cuda:0')\n",
      "epoch  97\n",
      "training loss:  0.3659908\n",
      "validation loss:  0.7700349\n",
      "validation accuracy:  tensor(0.7700, device='cuda:0')\n",
      "epoch  98\n",
      "training loss:  0.3644866\n",
      "validation loss:  0.7227885\n",
      "validation accuracy:  tensor(0.7707, device='cuda:0')\n",
      "epoch  99\n",
      "training loss:  0.36197242\n",
      "validation loss:  0.8610319\n",
      "validation accuracy:  tensor(0.7313, device='cuda:0')\n",
      "epoch  100\n",
      "training loss:  0.3602186\n",
      "validation loss:  0.79135776\n",
      "validation accuracy:  tensor(0.7667, device='cuda:0')\n",
      "epoch  101\n",
      "training loss:  0.35904044\n",
      "validation loss:  0.6645477\n",
      "validation accuracy:  tensor(0.7793, device='cuda:0')\n",
      "epoch  102\n",
      "training loss:  0.35666612\n",
      "validation loss:  0.8534882\n",
      "validation accuracy:  tensor(0.7153, device='cuda:0')\n",
      "epoch  103\n",
      "training loss:  0.3553891\n",
      "validation loss:  0.6596898\n",
      "validation accuracy:  tensor(0.7860, device='cuda:0')\n",
      "epoch  104\n",
      "training loss:  0.35316563\n",
      "validation loss:  0.72648543\n",
      "validation accuracy:  tensor(0.7773, device='cuda:0')\n",
      "epoch  105\n",
      "training loss:  0.35173386\n",
      "validation loss:  0.68408495\n",
      "validation accuracy:  tensor(0.7887, device='cuda:0')\n",
      "epoch  106\n",
      "training loss:  0.34950113\n",
      "validation loss:  0.87700987\n",
      "validation accuracy:  tensor(0.7340, device='cuda:0')\n",
      "epoch  107\n",
      "training loss:  0.34802258\n",
      "validation loss:  0.6653122\n",
      "validation accuracy:  tensor(0.7793, device='cuda:0')\n",
      "epoch  108\n",
      "training loss:  0.34572503\n",
      "validation loss:  0.7156792\n",
      "validation accuracy:  tensor(0.7673, device='cuda:0')\n",
      "epoch  109\n",
      "training loss:  0.34402537\n",
      "validation loss:  0.670546\n",
      "validation accuracy:  tensor(0.7740, device='cuda:0')\n",
      "epoch  110\n",
      "training loss:  0.34179667\n",
      "validation loss:  0.7917536\n",
      "validation accuracy:  tensor(0.7540, device='cuda:0')\n",
      "epoch  111\n",
      "training loss:  0.33985302\n",
      "validation loss:  0.7461535\n",
      "validation accuracy:  tensor(0.7787, device='cuda:0')\n",
      "epoch  112\n",
      "training loss:  0.33758578\n",
      "validation loss:  0.7583642\n",
      "validation accuracy:  tensor(0.7887, device='cuda:0')\n",
      "epoch  113\n",
      "training loss:  0.3355159\n",
      "validation loss:  0.7820293\n",
      "validation accuracy:  tensor(0.7867, device='cuda:0')\n",
      "epoch  114\n",
      "training loss:  0.33335683\n",
      "validation loss:  0.83014154\n",
      "validation accuracy:  tensor(0.7693, device='cuda:0')\n",
      "epoch  115\n",
      "training loss:  0.33110055\n",
      "validation loss:  0.86819094\n",
      "validation accuracy:  tensor(0.7547, device='cuda:0')\n",
      "epoch  116\n",
      "training loss:  0.32896107\n",
      "validation loss:  0.8314975\n",
      "validation accuracy:  tensor(0.7720, device='cuda:0')\n",
      "epoch  117\n",
      "training loss:  0.3267349\n",
      "validation loss:  0.87220955\n",
      "validation accuracy:  tensor(0.7640, device='cuda:0')\n",
      "epoch  118\n",
      "training loss:  0.32463086\n",
      "validation loss:  0.88184536\n",
      "validation accuracy:  tensor(0.7553, device='cuda:0')\n",
      "epoch  119\n",
      "training loss:  0.32239544\n",
      "validation loss:  0.94181323\n",
      "validation accuracy:  tensor(0.7473, device='cuda:0')\n",
      "epoch  120\n",
      "training loss:  0.32028076\n",
      "validation loss:  0.922887\n",
      "validation accuracy:  tensor(0.7700, device='cuda:0')\n",
      "epoch  121\n",
      "training loss:  0.31810522\n",
      "validation loss:  0.9540173\n",
      "validation accuracy:  tensor(0.7720, device='cuda:0')\n",
      "epoch  122\n",
      "training loss:  0.31601605\n",
      "validation loss:  0.9668107\n",
      "validation accuracy:  tensor(0.7653, device='cuda:0')\n",
      "epoch  123\n",
      "training loss:  0.3138171\n",
      "validation loss:  1.0074145\n",
      "validation accuracy:  tensor(0.7460, device='cuda:0')\n",
      "epoch  124\n",
      "training loss:  0.31173453\n",
      "validation loss:  0.9768529\n",
      "validation accuracy:  tensor(0.7667, device='cuda:0')\n",
      "epoch  125\n",
      "training loss:  0.3095832\n",
      "validation loss:  1.013003\n",
      "validation accuracy:  tensor(0.7633, device='cuda:0')\n",
      "epoch  126\n",
      "training loss:  0.30752927\n",
      "validation loss:  1.0101295\n",
      "validation accuracy:  tensor(0.7547, device='cuda:0')\n",
      "epoch  127\n",
      "training loss:  0.30540603\n",
      "validation loss:  1.0543917\n",
      "validation accuracy:  tensor(0.7520, device='cuda:0')\n",
      "epoch  128\n",
      "training loss:  0.30334616\n",
      "validation loss:  1.0654131\n",
      "validation accuracy:  tensor(0.7673, device='cuda:0')\n",
      "epoch  129\n",
      "training loss:  0.30126083\n",
      "validation loss:  1.0959662\n",
      "validation accuracy:  tensor(0.7713, device='cuda:0')\n",
      "epoch  130\n",
      "training loss:  0.29923925\n",
      "validation loss:  1.1126513\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  131\n",
      "training loss:  0.29716823\n",
      "validation loss:  1.1537209\n",
      "validation accuracy:  tensor(0.7520, device='cuda:0')\n",
      "epoch  132\n",
      "training loss:  0.2951775\n",
      "validation loss:  1.126733\n",
      "validation accuracy:  tensor(0.7667, device='cuda:0')\n",
      "epoch  133\n",
      "training loss:  0.29314765\n",
      "validation loss:  1.1482227\n",
      "validation accuracy:  tensor(0.7713, device='cuda:0')\n",
      "epoch  134\n",
      "training loss:  0.29119307\n",
      "validation loss:  1.1520364\n",
      "validation accuracy:  tensor(0.7647, device='cuda:0')\n",
      "epoch  135\n",
      "training loss:  0.28919065\n",
      "validation loss:  1.1960083\n",
      "validation accuracy:  tensor(0.7487, device='cuda:0')\n",
      "epoch  136\n",
      "training loss:  0.28726292\n",
      "validation loss:  1.1872786\n",
      "validation accuracy:  tensor(0.7660, device='cuda:0')\n",
      "epoch  137\n",
      "training loss:  0.28530148\n",
      "validation loss:  1.2158946\n",
      "validation accuracy:  tensor(0.7727, device='cuda:0')\n",
      "epoch  138\n",
      "training loss:  0.28340513\n",
      "validation loss:  1.2103684\n",
      "validation accuracy:  tensor(0.7680, device='cuda:0')\n",
      "epoch  139\n",
      "training loss:  0.28148475\n",
      "validation loss:  1.2320352\n",
      "validation accuracy:  tensor(0.7567, device='cuda:0')\n",
      "epoch  140\n",
      "training loss:  0.27960178\n",
      "validation loss:  1.23577\n",
      "validation accuracy:  tensor(0.7587, device='cuda:0')\n",
      "epoch  141\n",
      "training loss:  0.2777306\n",
      "validation loss:  1.2436652\n",
      "validation accuracy:  tensor(0.7687, device='cuda:0')\n",
      "epoch  142\n",
      "training loss:  0.27587855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss:  1.2629489\n",
      "validation accuracy:  tensor(0.7693, device='cuda:0')\n",
      "epoch  143\n",
      "training loss:  0.27405432\n",
      "validation loss:  1.272558\n",
      "validation accuracy:  tensor(0.7633, device='cuda:0')\n",
      "epoch  144\n",
      "training loss:  0.27223447\n",
      "validation loss:  1.3146169\n",
      "validation accuracy:  tensor(0.7540, device='cuda:0')\n",
      "epoch  145\n",
      "training loss:  0.2704475\n",
      "validation loss:  1.3227218\n",
      "validation accuracy:  tensor(0.7587, device='cuda:0')\n",
      "epoch  146\n",
      "training loss:  0.26867032\n",
      "validation loss:  1.332713\n",
      "validation accuracy:  tensor(0.7693, device='cuda:0')\n",
      "epoch  147\n",
      "training loss:  0.26691562\n",
      "validation loss:  1.350672\n",
      "validation accuracy:  tensor(0.7680, device='cuda:0')\n",
      "epoch  148\n",
      "training loss:  0.265184\n",
      "validation loss:  1.3721251\n",
      "validation accuracy:  tensor(0.7667, device='cuda:0')\n",
      "epoch  149\n",
      "training loss:  0.26346436\n",
      "validation loss:  1.3984272\n",
      "validation accuracy:  tensor(0.7540, device='cuda:0')\n",
      "epoch  150\n",
      "training loss:  0.26176956\n",
      "validation loss:  1.4105804\n",
      "validation accuracy:  tensor(0.7587, device='cuda:0')\n",
      "epoch  151\n",
      "training loss:  0.26009175\n",
      "validation loss:  1.4217262\n",
      "validation accuracy:  tensor(0.7660, device='cuda:0')\n",
      "epoch  152\n",
      "training loss:  0.25843057\n",
      "validation loss:  1.4397426\n",
      "validation accuracy:  tensor(0.7653, device='cuda:0')\n",
      "epoch  153\n",
      "training loss:  0.25679085\n",
      "validation loss:  1.4581823\n",
      "validation accuracy:  tensor(0.7667, device='cuda:0')\n",
      "epoch  154\n",
      "training loss:  0.25516546\n",
      "validation loss:  1.4722726\n",
      "validation accuracy:  tensor(0.7653, device='cuda:0')\n",
      "epoch  155\n",
      "training loss:  0.2535589\n",
      "validation loss:  1.4843456\n",
      "validation accuracy:  tensor(0.7647, device='cuda:0')\n",
      "epoch  156\n",
      "training loss:  0.25197083\n",
      "validation loss:  1.4948255\n",
      "validation accuracy:  tensor(0.7653, device='cuda:0')\n",
      "epoch  157\n",
      "training loss:  0.25039908\n",
      "validation loss:  1.5106772\n",
      "validation accuracy:  tensor(0.7687, device='cuda:0')\n",
      "epoch  158\n",
      "training loss:  0.24884799\n",
      "validation loss:  1.518596\n",
      "validation accuracy:  tensor(0.7667, device='cuda:0')\n",
      "epoch  159\n",
      "training loss:  0.2473131\n",
      "validation loss:  1.5258467\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  160\n",
      "training loss:  0.2457964\n",
      "validation loss:  1.5369124\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  161\n",
      "training loss:  0.24429825\n",
      "validation loss:  1.5485854\n",
      "validation accuracy:  tensor(0.7647, device='cuda:0')\n",
      "epoch  162\n",
      "training loss:  0.24281597\n",
      "validation loss:  1.5647441\n",
      "validation accuracy:  tensor(0.7693, device='cuda:0')\n",
      "epoch  163\n",
      "training loss:  0.24135204\n",
      "validation loss:  1.5751266\n",
      "validation accuracy:  tensor(0.7680, device='cuda:0')\n",
      "epoch  164\n",
      "training loss:  0.23990464\n",
      "validation loss:  1.5832998\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  165\n",
      "training loss:  0.23847337\n",
      "validation loss:  1.5951573\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  166\n",
      "training loss:  0.2370594\n",
      "validation loss:  1.6076477\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  167\n",
      "training loss:  0.23566103\n",
      "validation loss:  1.6216499\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  168\n",
      "training loss:  0.2342788\n",
      "validation loss:  1.6421984\n",
      "validation accuracy:  tensor(0.7640, device='cuda:0')\n",
      "epoch  169\n",
      "training loss:  0.23291264\n",
      "validation loss:  1.6514179\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  170\n",
      "training loss:  0.23156151\n",
      "validation loss:  1.6684551\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  171\n",
      "training loss:  0.23022614\n",
      "validation loss:  1.6778389\n",
      "validation accuracy:  tensor(0.7587, device='cuda:0')\n",
      "epoch  172\n",
      "training loss:  0.2289057\n",
      "validation loss:  1.6875335\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  173\n",
      "training loss:  0.2275999\n",
      "validation loss:  1.6963863\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  174\n",
      "training loss:  0.22630912\n",
      "validation loss:  1.7037183\n",
      "validation accuracy:  tensor(0.7573, device='cuda:0')\n",
      "epoch  175\n",
      "training loss:  0.22503239\n",
      "validation loss:  1.7110404\n",
      "validation accuracy:  tensor(0.7573, device='cuda:0')\n",
      "epoch  176\n",
      "training loss:  0.22377\n",
      "validation loss:  1.7188851\n",
      "validation accuracy:  tensor(0.7580, device='cuda:0')\n",
      "epoch  177\n",
      "training loss:  0.22252157\n",
      "validation loss:  1.727729\n",
      "validation accuracy:  tensor(0.7587, device='cuda:0')\n",
      "epoch  178\n",
      "training loss:  0.22128673\n",
      "validation loss:  1.7368225\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  179\n",
      "training loss:  0.22006561\n",
      "validation loss:  1.7430736\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  180\n",
      "training loss:  0.21885763\n",
      "validation loss:  1.7572842\n",
      "validation accuracy:  tensor(0.7587, device='cuda:0')\n",
      "epoch  181\n",
      "training loss:  0.21766281\n",
      "validation loss:  1.7637938\n",
      "validation accuracy:  tensor(0.7587, device='cuda:0')\n",
      "epoch  182\n",
      "training loss:  0.2164809\n",
      "validation loss:  1.7715435\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  183\n",
      "training loss:  0.21531159\n",
      "validation loss:  1.7794532\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  184\n",
      "training loss:  0.2141549\n",
      "validation loss:  1.7856673\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  185\n",
      "training loss:  0.2130104\n",
      "validation loss:  1.7918768\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  186\n",
      "training loss:  0.21187809\n",
      "validation loss:  1.7985661\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  187\n",
      "training loss:  0.21075766\n",
      "validation loss:  1.8064828\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  188\n",
      "training loss:  0.209649\n",
      "validation loss:  1.8211504\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  189\n",
      "training loss:  0.20855191\n",
      "validation loss:  1.8270661\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  190\n",
      "training loss:  0.20746617\n",
      "validation loss:  1.8328043\n",
      "validation accuracy:  tensor(0.7627, device='cuda:0')\n",
      "epoch  191\n",
      "training loss:  0.2063917\n",
      "validation loss:  1.8392745\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  192\n",
      "training loss:  0.20532826\n",
      "validation loss:  1.8462663\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  193\n",
      "training loss:  0.2042757\n",
      "validation loss:  1.8522297\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  194\n",
      "training loss:  0.20323387\n",
      "validation loss:  1.8577361\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  195\n",
      "training loss:  0.20220259\n",
      "validation loss:  1.8715639\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  196\n",
      "training loss:  0.2011817\n",
      "validation loss:  1.8782905\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  197\n",
      "training loss:  0.20017105\n",
      "validation loss:  1.8839738\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  198\n",
      "training loss:  0.19917051\n",
      "validation loss:  1.8976927\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  199\n",
      "training loss:  0.19817992\n",
      "validation loss:  1.9034144\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  200\n",
      "training loss:  0.19719912\n",
      "validation loss:  1.9097645\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  201\n",
      "training loss:  0.19622798\n",
      "validation loss:  1.9157532\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  202\n",
      "training loss:  0.19526638\n",
      "validation loss:  1.9210498\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  203\n",
      "training loss:  0.19431414\n",
      "validation loss:  1.9267168\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  204\n",
      "training loss:  0.19337113\n",
      "validation loss:  1.9326884\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  205\n",
      "training loss:  0.19243726\n",
      "validation loss:  1.9387416\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  206\n",
      "training loss:  0.19151235\n",
      "validation loss:  1.9515243\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  207\n",
      "training loss:  0.19059628\n",
      "validation loss:  1.9560547\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  208\n",
      "training loss:  0.18968897\n",
      "validation loss:  1.9618083\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  209\n",
      "training loss:  0.18879025\n",
      "validation loss:  1.9674199\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  210\n",
      "training loss:  0.1879\n",
      "validation loss:  1.9724448\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  211\n",
      "training loss:  0.18701813\n",
      "validation loss:  1.9846765\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  212\n",
      "training loss:  0.18614452\n",
      "validation loss:  1.9902503\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  213\n",
      "training loss:  0.18527901\n",
      "validation loss:  1.995721\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  214\n",
      "training loss:  0.18442154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss:  2.0003586\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  215\n",
      "training loss:  0.18357198\n",
      "validation loss:  2.0206406\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  216\n",
      "training loss:  0.18273023\n",
      "validation loss:  2.0259652\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  217\n",
      "training loss:  0.18189615\n",
      "validation loss:  2.03091\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  218\n",
      "training loss:  0.18106967\n",
      "validation loss:  2.0353503\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  219\n",
      "training loss:  0.1802507\n",
      "validation loss:  2.0407476\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  220\n",
      "training loss:  0.17943911\n",
      "validation loss:  2.046001\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  221\n",
      "training loss:  0.1786348\n",
      "validation loss:  2.0503793\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  222\n",
      "training loss:  0.17783768\n",
      "validation loss:  2.0551448\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  223\n",
      "training loss:  0.17704768\n",
      "validation loss:  2.060089\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  224\n",
      "training loss:  0.17626464\n",
      "validation loss:  2.0649238\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  225\n",
      "training loss:  0.17548855\n",
      "validation loss:  2.0690477\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  226\n",
      "training loss:  0.17471927\n",
      "validation loss:  2.0735781\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  227\n",
      "training loss:  0.1739567\n",
      "validation loss:  2.0783985\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  228\n",
      "training loss:  0.1732008\n",
      "validation loss:  2.0830138\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  229\n",
      "training loss:  0.17245144\n",
      "validation loss:  2.0872464\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  230\n",
      "training loss:  0.17170854\n",
      "validation loss:  2.0918982\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  231\n",
      "training loss:  0.17097205\n",
      "validation loss:  2.096022\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  232\n",
      "training loss:  0.17024186\n",
      "validation loss:  2.0999517\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  233\n",
      "training loss:  0.16951789\n",
      "validation loss:  2.1045473\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  234\n",
      "training loss:  0.16880007\n",
      "validation loss:  2.1088233\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  235\n",
      "training loss:  0.16808833\n",
      "validation loss:  2.120398\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  236\n",
      "training loss:  0.16738257\n",
      "validation loss:  2.1249044\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  237\n",
      "training loss:  0.16668275\n",
      "validation loss:  2.1291091\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  238\n",
      "training loss:  0.16598874\n",
      "validation loss:  2.140612\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  239\n",
      "training loss:  0.16530055\n",
      "validation loss:  2.144754\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  240\n",
      "training loss:  0.16461803\n",
      "validation loss:  2.1491876\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  241\n",
      "training loss:  0.16394114\n",
      "validation loss:  2.16111\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  242\n",
      "training loss:  0.16326982\n",
      "validation loss:  2.1729152\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  243\n",
      "training loss:  0.16260397\n",
      "validation loss:  2.17677\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  244\n",
      "training loss:  0.16194357\n",
      "validation loss:  2.1806316\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  245\n",
      "training loss:  0.16128851\n",
      "validation loss:  2.1846998\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  246\n",
      "training loss:  0.16063875\n",
      "validation loss:  2.188728\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  247\n",
      "training loss:  0.15999423\n",
      "validation loss:  2.1925137\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  248\n",
      "training loss:  0.15935488\n",
      "validation loss:  2.196438\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  249\n",
      "training loss:  0.15872063\n",
      "validation loss:  2.1998134\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  250\n",
      "training loss:  0.15809144\n",
      "validation loss:  2.2035944\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  251\n",
      "training loss:  0.1574672\n",
      "validation loss:  2.207499\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  252\n",
      "training loss:  0.15684791\n",
      "validation loss:  2.2109907\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  253\n",
      "training loss:  0.15623349\n",
      "validation loss:  2.2148297\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  254\n",
      "training loss:  0.1556239\n",
      "validation loss:  2.2184956\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  255\n",
      "training loss:  0.15501902\n",
      "validation loss:  2.222395\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  256\n",
      "training loss:  0.15441887\n",
      "validation loss:  2.2261002\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  257\n",
      "training loss:  0.15382336\n",
      "validation loss:  2.2371736\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  258\n",
      "training loss:  0.15323244\n",
      "validation loss:  2.240788\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  259\n",
      "training loss:  0.15264606\n",
      "validation loss:  2.2441666\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  260\n",
      "training loss:  0.15206417\n",
      "validation loss:  2.247558\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  261\n",
      "training loss:  0.15148672\n",
      "validation loss:  2.251292\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  262\n",
      "training loss:  0.15091366\n",
      "validation loss:  2.254344\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  263\n",
      "training loss:  0.15034494\n",
      "validation loss:  2.2583394\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  264\n",
      "training loss:  0.14978048\n",
      "validation loss:  2.2617323\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  265\n",
      "training loss:  0.14922029\n",
      "validation loss:  2.265208\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  266\n",
      "training loss:  0.14866428\n",
      "validation loss:  2.2684882\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  267\n",
      "training loss:  0.14811242\n",
      "validation loss:  2.2719421\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  268\n",
      "training loss:  0.14756465\n",
      "validation loss:  2.2750366\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  269\n",
      "training loss:  0.14702092\n",
      "validation loss:  2.2781627\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  270\n",
      "training loss:  0.14648122\n",
      "validation loss:  2.2814283\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  271\n",
      "training loss:  0.14594546\n",
      "validation loss:  2.2843866\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  272\n",
      "training loss:  0.14541365\n",
      "validation loss:  2.2878547\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  273\n",
      "training loss:  0.1448857\n",
      "validation loss:  2.2905552\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  274\n",
      "training loss:  0.1443616\n",
      "validation loss:  2.2939193\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  275\n",
      "training loss:  0.14384127\n",
      "validation loss:  2.3044682\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  276\n",
      "training loss:  0.14332472\n",
      "validation loss:  2.3079448\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  277\n",
      "training loss:  0.14281188\n",
      "validation loss:  2.3103628\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  278\n",
      "training loss:  0.1423027\n",
      "validation loss:  2.3146238\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  279\n",
      "training loss:  0.14179717\n",
      "validation loss:  2.3157158\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  280\n",
      "training loss:  0.14129525\n",
      "validation loss:  2.3216925\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  281\n",
      "training loss:  0.14079691\n",
      "validation loss:  2.3206174\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  282\n",
      "training loss:  0.1403021\n",
      "validation loss:  2.3270035\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  283\n",
      "training loss:  0.13981079\n",
      "validation loss:  2.3264112\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  284\n",
      "training loss:  0.13932288\n",
      "validation loss:  2.330793\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  285\n",
      "training loss:  0.13883835\n",
      "validation loss:  2.3333824\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  286\n",
      "training loss:  0.13835719\n",
      "validation loss:  2.3343344\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  287\n",
      "training loss:  0.13787939\n",
      "validation loss:  2.3393922\n",
      "validation accuracy:  tensor(0.7587, device='cuda:0')\n",
      "epoch  288\n",
      "training loss:  0.1374049\n",
      "validation loss:  2.3465195\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  289\n",
      "training loss:  0.1369337\n",
      "validation loss:  2.3441365\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  290\n",
      "training loss:  0.13646571\n",
      "validation loss:  2.344211\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  291\n",
      "training loss:  0.1360009\n",
      "validation loss:  2.3473094\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  292\n",
      "training loss:  0.13553928\n",
      "validation loss:  2.350305\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  293\n",
      "training loss:  0.13508078\n",
      "validation loss:  2.3583944\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  294\n",
      "training loss:  0.1346254\n",
      "validation loss:  2.3556337\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  295\n",
      "training loss:  0.13417313\n",
      "validation loss:  2.3635015\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  296\n",
      "training loss:  0.13372387\n",
      "validation loss:  2.3678217\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  297\n",
      "training loss:  0.13327762\n",
      "validation loss:  2.3686535\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  298\n",
      "training loss:  0.13283436\n",
      "validation loss:  2.3708863\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  299\n",
      "training loss:  0.13239403\n",
      "validation loss:  2.3734713\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  300\n",
      "training loss:  0.13195662\n",
      "validation loss:  2.375671\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  301\n",
      "training loss:  0.13152213\n",
      "validation loss:  2.3782969\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  302\n",
      "training loss:  0.1310905\n",
      "validation loss:  2.3793476\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  303\n",
      "training loss:  0.13066173\n",
      "validation loss:  2.383522\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  304\n",
      "training loss:  0.13023575\n",
      "validation loss:  2.383737\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  305\n",
      "training loss:  0.12981255\n",
      "validation loss:  2.388063\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  306\n",
      "training loss:  0.12939212\n",
      "validation loss:  2.3881757\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  307\n",
      "training loss:  0.12897441\n",
      "validation loss:  2.3916628\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  308\n",
      "training loss:  0.12855938\n",
      "validation loss:  2.3927655\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  309\n",
      "training loss:  0.12814704\n",
      "validation loss:  2.3953817\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  310\n",
      "training loss:  0.12773734\n",
      "validation loss:  2.4049609\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  311\n",
      "training loss:  0.12733027\n",
      "validation loss:  2.4068708\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  312\n",
      "training loss:  0.12692581\n",
      "validation loss:  2.4092178\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  313\n",
      "training loss:  0.12652393\n",
      "validation loss:  2.4102783\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  314\n",
      "training loss:  0.12612458\n",
      "validation loss:  2.41366\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  315\n",
      "training loss:  0.12572776\n",
      "validation loss:  2.4144204\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  316\n",
      "training loss:  0.12533346\n",
      "validation loss:  2.4181027\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  317\n",
      "training loss:  0.12494164\n",
      "validation loss:  2.4178877\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  318\n",
      "training loss:  0.12455228\n",
      "validation loss:  2.422882\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  319\n",
      "training loss:  0.12416537\n",
      "validation loss:  2.4211216\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  320\n",
      "training loss:  0.12378089\n",
      "validation loss:  2.4277115\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  321\n",
      "training loss:  0.123398826\n",
      "validation loss:  2.4238234\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  322\n",
      "training loss:  0.12301916\n",
      "validation loss:  2.4317179\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  323\n",
      "training loss:  0.12264185\n",
      "validation loss:  2.4272392\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  324\n",
      "training loss:  0.12226684\n",
      "validation loss:  2.433859\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  325\n",
      "training loss:  0.121894084\n",
      "validation loss:  2.4316647\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  326\n",
      "training loss:  0.121523574\n",
      "validation loss:  2.4357085\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  327\n",
      "training loss:  0.1211553\n",
      "validation loss:  2.4367406\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  328\n",
      "training loss:  0.12078926\n",
      "validation loss:  2.4378252\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  329\n",
      "training loss:  0.120425425\n",
      "validation loss:  2.4407716\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  330\n",
      "training loss:  0.12006382\n",
      "validation loss:  2.4396331\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  331\n",
      "training loss:  0.119704396\n",
      "validation loss:  2.4449484\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  332\n",
      "training loss:  0.11934715\n",
      "validation loss:  2.4418623\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  333\n",
      "training loss:  0.11899206\n",
      "validation loss:  2.4484272\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  334\n",
      "training loss:  0.118639104\n",
      "validation loss:  2.444728\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  335\n",
      "training loss:  0.118288234\n",
      "validation loss:  2.451267\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  336\n",
      "training loss:  0.117939435\n",
      "validation loss:  2.4482362\n",
      "validation accuracy:  tensor(0.7593, device='cuda:0')\n",
      "epoch  337\n",
      "training loss:  0.11759269\n",
      "validation loss:  2.4536388\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  338\n",
      "training loss:  0.11724797\n",
      "validation loss:  2.4520044\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  339\n",
      "training loss:  0.11690527\n",
      "validation loss:  2.4554412\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  340\n",
      "training loss:  0.116564564\n",
      "validation loss:  2.4557023\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  341\n",
      "training loss:  0.11622585\n",
      "validation loss:  2.4577546\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  342\n",
      "training loss:  0.1158891\n",
      "validation loss:  2.4591851\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  343\n",
      "training loss:  0.11555431\n",
      "validation loss:  2.4599438\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  344\n",
      "training loss:  0.11522147\n",
      "validation loss:  2.4626286\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  345\n",
      "training loss:  0.114890546\n",
      "validation loss:  2.4625068\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  346\n",
      "training loss:  0.114561535\n",
      "validation loss:  2.466016\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  347\n",
      "training loss:  0.11423443\n",
      "validation loss:  2.4725995\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  348\n",
      "training loss:  0.1139092\n",
      "validation loss:  2.4696007\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  349\n",
      "training loss:  0.113585845\n",
      "validation loss:  2.474993\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  350\n",
      "training loss:  0.11326435\n",
      "validation loss:  2.473767\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  351\n",
      "training loss:  0.11294473\n",
      "validation loss:  2.476876\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  352\n",
      "training loss:  0.11262695\n",
      "validation loss:  2.477553\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  353\n",
      "training loss:  0.11231099\n",
      "validation loss:  2.486656\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  354\n",
      "training loss:  0.11199682\n",
      "validation loss:  2.4796226\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  355\n",
      "training loss:  0.111684404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss:  2.4821227\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  356\n",
      "training loss:  0.111373685\n",
      "validation loss:  2.4803555\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  357\n",
      "training loss:  0.111064665\n",
      "validation loss:  2.485421\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  358\n",
      "training loss:  0.110757336\n",
      "validation loss:  2.4817173\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  359\n",
      "training loss:  0.11045169\n",
      "validation loss:  2.4884164\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  360\n",
      "training loss:  0.11014772\n",
      "validation loss:  2.4833505\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  361\n",
      "training loss:  0.10984544\n",
      "validation loss:  2.491598\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  362\n",
      "training loss:  0.10954481\n",
      "validation loss:  2.4926517\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  363\n",
      "training loss:  0.10924584\n",
      "validation loss:  2.494527\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  364\n",
      "training loss:  0.10894851\n",
      "validation loss:  2.4947534\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  365\n",
      "training loss:  0.1086528\n",
      "validation loss:  2.4897554\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  366\n",
      "training loss:  0.10835871\n",
      "validation loss:  2.4964037\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  367\n",
      "training loss:  0.108066216\n",
      "validation loss:  2.492737\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  368\n",
      "training loss:  0.10777534\n",
      "validation loss:  2.513072\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  369\n",
      "training loss:  0.107486054\n",
      "validation loss:  2.4967697\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  370\n",
      "training loss:  0.10719838\n",
      "validation loss:  2.5144598\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  371\n",
      "training loss:  0.10691231\n",
      "validation loss:  2.4999847\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  372\n",
      "training loss:  0.10662781\n",
      "validation loss:  2.5157838\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  373\n",
      "training loss:  0.10634485\n",
      "validation loss:  2.5022354\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  374\n",
      "training loss:  0.106063366\n",
      "validation loss:  2.5186605\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  375\n",
      "training loss:  0.10578332\n",
      "validation loss:  2.5024736\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  376\n",
      "training loss:  0.105504714\n",
      "validation loss:  2.5213153\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  377\n",
      "training loss:  0.105227545\n",
      "validation loss:  2.5106454\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  378\n",
      "training loss:  0.104951814\n",
      "validation loss:  2.5164485\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  379\n",
      "training loss:  0.10467753\n",
      "validation loss:  2.5199788\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  380\n",
      "training loss:  0.10440467\n",
      "validation loss:  2.518856\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  381\n",
      "training loss:  0.10413325\n",
      "validation loss:  2.5217564\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  382\n",
      "training loss:  0.10386323\n",
      "validation loss:  2.520779\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  383\n",
      "training loss:  0.10359462\n",
      "validation loss:  2.523937\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  384\n",
      "training loss:  0.103327416\n",
      "validation loss:  2.5302684\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  385\n",
      "training loss:  0.103061594\n",
      "validation loss:  2.5266874\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  386\n",
      "training loss:  0.10279716\n",
      "validation loss:  2.5318038\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  387\n",
      "training loss:  0.10253411\n",
      "validation loss:  2.5296943\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  388\n",
      "training loss:  0.10227244\n",
      "validation loss:  2.5330002\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  389\n",
      "training loss:  0.10201217\n",
      "validation loss:  2.518182\n",
      "validation accuracy:  tensor(0.7613, device='cuda:0')\n",
      "epoch  390\n",
      "training loss:  0.101753294\n",
      "validation loss:  2.549076\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  391\n",
      "training loss:  0.101495795\n",
      "validation loss:  2.5204847\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  392\n",
      "training loss:  0.1012396\n",
      "validation loss:  2.5512662\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  393\n",
      "training loss:  0.10098465\n",
      "validation loss:  2.5357347\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  394\n",
      "training loss:  0.10073093\n",
      "validation loss:  2.5388064\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  395\n",
      "training loss:  0.10047845\n",
      "validation loss:  2.5360065\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  396\n",
      "training loss:  0.1002272\n",
      "validation loss:  2.5409758\n",
      "validation accuracy:  tensor(0.7600, device='cuda:0')\n",
      "epoch  397\n",
      "training loss:  0.0999772\n",
      "validation loss:  2.5369194\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n",
      "epoch  398\n",
      "training loss:  0.09972845\n",
      "validation loss:  2.542818\n",
      "validation accuracy:  tensor(0.7607, device='cuda:0')\n",
      "epoch  399\n",
      "training loss:  0.09948094\n",
      "validation loss:  2.5388143\n",
      "validation accuracy:  tensor(0.7620, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Train network\n",
    "cnt = 0\n",
    "average_losses = []\n",
    "average_val_losses = []\n",
    "acc = []\n",
    "cur_loss = []\n",
    "min_validation = 10000.0\n",
    "min_val_epoch = 0\n",
    "for epoch in range(400):\n",
    "    net.train()\n",
    "    #zero the gradient\n",
    "    adam.zero_grad()\n",
    "    #Get output of network\n",
    "    probs = net(train_features_tensor)\n",
    "    #compute loss\n",
    "    loss = loss_func(probs,train_labels_tensor)\n",
    "    #compute the backward gradient and move network in that direction\n",
    "    loss.backward()\n",
    "    adam.step()\n",
    "    #gather loss\n",
    "    cur_loss.append(loss.detach().cpu().numpy())\n",
    "    print(\"epoch \",epoch)\n",
    "    print(\"training loss: \", np.mean(cur_loss))\n",
    "    net.eval()\n",
    "    probs_val = net(val_features_tensor)\n",
    "    loss_val = loss_func(probs_val,val_labels_tensor)\n",
    "    print(\"validation loss: \", np.mean(loss_val.detach().cpu().numpy()))\n",
    "    print(\"validation accuracy: \", accuracy(net,val_features_tensor,val_labels_tensor))\n",
    "    #Save model if validation is min\n",
    "    if min_validation > np.mean(loss_val.detach().cpu().numpy()):\n",
    "        min_validation = np.mean(loss_val.detach().cpu().numpy())\n",
    "        min_val_epoch = epoch\n",
    "        torch.save(net.state_dict(), './net_parameters_kaggle.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 1., 1.]], device='cuda:0', grad_fn=<TBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(torch.round(probs[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels_tensor[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(torch.t(torch.round(probs[0:5])) - val_labels_tensor[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Shallow_Network()\n",
    "checkpoint = torch.load('./net_parameters_kaggle.pth')\n",
    "net.load_state_dict(checkpoint)\n",
    "net = net.to(device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_val = net(val_features_tensor)\n",
    "loss_val = loss_func(probs_val,val_labels_tensor)\n",
    "print(\"validation loss: \", np.mean(loss_val.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(net,val_features_tensor,val_labels_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = val_set.loc[val_set.index.difference(val_random_sample.index)]\n",
    "test_random_sample_tokenized = test_set['text_cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "test_padded, test_len = pad_token_list(test_random_sample_tokenized.values)\n",
    "test_features, mask = get_embeddings_from_sample(test_padded, model)\n",
    "test_features_tensor = torch.tensor(np.asarray(test_features))\n",
    "test_features_tensor = test_features_tensor.to(device)\n",
    "test_labels_tensor =  torch.tensor(np.asarray(test_set['target']).astype(np.int))\n",
    "test_labels_tensor = test_labels_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(net,test_features_tensor,test_labels_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline only html tag and special character cleaning yielded 81.8% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:39.547585Z",
     "start_time": "2020-03-11T15:36:39.532169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:39.962932Z",
     "start_time": "2020-03-11T15:36:39.932119Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop_duplicates(subset='text_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:48.645628Z",
     "start_time": "2020-03-11T15:36:48.630451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6957, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:36:49.469026Z",
     "start_time": "2020-03-11T15:36:49.431710Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text target  \\\n",
       "1  Our Deeds are the Reason of this #earthquake M...      1   \n",
       "2             Forest fire near La Ronge Sask. Canada      1   \n",
       "3  All residents asked to 'shelter in place' are ...      1   \n",
       "4  13,000 people receive #wildfires evacuation or...      1   \n",
       "5  Just got sent this photo from Ruby #Alaska as ...      1   \n",
       "\n",
       "                                        text_cleaned  \n",
       "1  Our Deeds are the Reason of this #earthquake M...  \n",
       "2             Forest fire near La Ronge Sask. Canada  \n",
       "3  All residents asked to 'shelter in place' are ...  \n",
       "4  13,000 people receive #wildfires evacuation or...  \n",
       "5  Just got sent this photo from Ruby #Alaska as ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ã¢\n",
    "&gt;\n",
    "&amp;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
